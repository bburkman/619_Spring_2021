{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "prostate-genome",
   "metadata": {},
   "source": [
    "# Data Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "motivated-request",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "floppy-rhythm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.9.1 (v3.9.1:1e5d33e9b9, Dec  7 2020, 12:10:52) \n",
      "[Clang 6.0 (clang-600.0.57)]\n",
      "pandas version: 1.2.3\n",
      "matplotlib version: 3.3.3\n",
      "NumPy version: 1.19.5\n",
      "SciPy version: 1.6.0\n",
      "IPython version: 7.21.0\n",
      "scikit-learn version: 0.24.1\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "2019_Crash_1_Database.csv\n",
      "CODE_TB.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print ('Python version: {}'.format(sys.version))\n",
    "import pandas as pd\n",
    "print ('pandas version: {}'.format(pd.__version__))\n",
    "import matplotlib\n",
    "print ('matplotlib version: {}'.format(matplotlib.__version__))\n",
    "import numpy as np\n",
    "print ('NumPy version: {}'.format(np.__version__))\n",
    "import scipy as sp\n",
    "print ('SciPy version: {}'.format(sp.__version__))\n",
    "import IPython\n",
    "print ('IPython version: {}'.format(IPython.__version__))\n",
    "import sklearn\n",
    "print ('scikit-learn version: {}'.format(sklearn.__version__))\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "import copy\n",
    "warnings.filterwarnings('ignore')\n",
    "print ('-*'*20)\n",
    "from subprocess import check_output\n",
    "print (check_output(['ls', './data']).decode('utf8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prime-drill",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-fortune",
   "metadata": {},
   "source": [
    "We will bring in the data as data_originalk, and make a deep copy, data_raw.\n",
    "Then we will process each column, copy it to data, and delete it from data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "centered-saskatchewan",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_original = pd.read_csv('./data/2019_Crash_1_Database.csv', parse_dates = ['crash_date', 'crash_hour', 'crash_time'])\n",
    "data_raw = data_original.copy(deep=True)\n",
    "data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-gardening",
   "metadata": {},
   "source": [
    "# Dependent Variable\n",
    "The dependent variable y=1 if somebody died, y=0 otherwise.  \n",
    "We have two fields that give us this information.  \n",
    "'num_tot_kil' [0, 1, 2, 3, 4], giving the number killed.\n",
    "\n",
    "'severity_cd' ['E' 'D' 'C' 'B' 'A'], with 'A' being 'Fatal.'\n",
    "\n",
    "Do these columns agree?  Yes (below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "junior-banking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "(array([], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "for x in ['num_tot_kil', 'severity_cd']:\n",
    "    print (data_raw[x].isnull().sum())\n",
    "A = np.where( (\n",
    "    (data_raw['num_tot_kil'] == 0) & (data_raw['severity_cd'] == 'A') |\n",
    "    (data_raw['num_tot_kil'] > 0) & (data_raw['severity_cd'] != 'A') \n",
    "))\n",
    "print (A)\n",
    "#A = np.where( (data_raw['num_tot_kil']>0 & data_raw['severity_cd']=='A'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "early-leeds",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['fatal'] = data_raw['num_tot_kil'].apply(lambda x: 1 if x>0 else x)\n",
    "for x in ['num_tot_kil', 'severity_cd']:\n",
    "    data_raw.drop([x], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjustable-vinyl",
   "metadata": {},
   "source": [
    "# No Idea What This Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "welcome-mistake",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in ['quadrant', 'spotted_by', 'city_cd', 'bypass']:\n",
    "    data_raw.drop([x], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "under-trance",
   "metadata": {},
   "source": [
    "# Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-wright",
   "metadata": {},
   "source": [
    "- crash_date\n",
    "- crash_hour\n",
    "- crash_year\n",
    "- crash_time\n",
    "\n",
    "The years are all the same.\n",
    "\n",
    "What might be interesting is the month and the day of week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "swedish-roots",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for x in ['crash_date', 'crash_hour']:\n",
    "    print (data_raw[x].isnull().sum())\n",
    "\n",
    "\n",
    "data['crash_month'] = data_raw['crash_date'].dt.month\n",
    "data['crash_dayofweek'] = data_raw['crash_date'].dt.dayofweek\n",
    "data['crash_hour'] = data_raw['crash_hour']\n",
    "\n",
    "data_raw.drop(['crash_date', 'crash_hour', 'crash_year', 'crash_time'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-teaching",
   "metadata": {},
   "source": [
    "# Direction\n",
    "I think I'll use just 'pri_road_dir,', which seems clean enough.  \n",
    "Change the blanks to 'Z'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "monetary-broadway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "travel_dirs ['    ', 'E   ', 'EE  ', 'EEE ', 'EEEE', 'EEEN', 'EEES', 'EEEW', 'EEN ', 'EENE', 'EENN', 'EENW', 'EES ', 'EESS', 'EESW', 'EEW ', 'EEWE', 'EEWW', 'EN  ', 'ENE ', 'ENEE', 'ENN ', 'ENNE', 'ENNN', 'ENNS', 'ENS ', 'ENSS', 'ENSW', 'ENW ', 'ENWN', 'ENWW', 'ES  ', 'ESE ', 'ESEE', 'ESN ', 'ESNE', 'ESNN', 'ESS ', 'ESSE', 'ESSS', 'ESSW', 'ESW ', 'ESWW', 'EW  ', 'EWE ', 'EWEE', 'EWN ', 'EWNN', 'EWS ', 'EWSS', 'EWW ', 'EWWE', 'EWWS', 'EWWW', 'N   ', 'NE  ', 'NEE ', 'NEEE', 'NEEW', 'NEN ', 'NES ', 'NESN', 'NESS', 'NEW ', 'NEWE', 'NN  ', 'NNE ', 'NNEE', 'NNES', 'NNN ', 'NNNE', 'NNNN', 'NNNS', 'NNNW', 'NNS ', 'NNSN', 'NNSS', 'NNW ', 'NNWN', 'NNWW', 'NS  ', 'NSE ', 'NSEE', 'NSEN', 'NSN ', 'NSNN', 'NSNW', 'NSS ', 'NSSE', 'NSSS', 'NSW ', 'NSWW', 'NW  ', 'NWE ', 'NWEE', 'NWEN', 'NWN ', 'NWNS', 'NWS ', 'NWSS', 'NWW ', 'NWWW', 'S   ', 'S S ', 'SE  ', 'SEE ', 'SEEE', 'SEN ', 'SENN', 'SES ', 'SESS', 'SEW ', 'SEWW', 'SN  ', 'SNE ', 'SNEN', 'SNN ', 'SNNN', 'SNNS', 'SNS ', 'SNSN', 'SNSS', 'SNW ', 'SNWW', 'SS  ', 'SSE ', 'SSEE', 'SSES', 'SSEW', 'SSN ', 'SSNN', 'SSNS', 'SSNW', 'SSS ', 'SSSE', 'SSSN', 'SSSS', 'SSSW', 'SSW ', 'SW  ', 'SWE ', 'SWEE', 'SWES', 'SWN ', 'SWS ', 'SWSN', 'SWSS', 'SWW ', 'SWWS', 'SWWW', 'W   ', 'WE  ', 'WEE ', 'WEEE', 'WEEN', 'WEEW', 'WEN ', 'WENN', 'WENW', 'WES ', 'WESS', 'WEW ', 'WEWE', 'WEWW', 'WN  ', 'WNE ', 'WNN ', 'WNNN', 'WNNS', 'WNS ', 'WNSS', 'WNW ', 'WS  ', 'WSE ', 'WSEE', 'WSEN', 'WSEW', 'WSN ', 'WSNN', 'WSS ', 'WSSS', 'WSW ', 'WSWS', 'WSWW', 'WW  ', 'WWE ', 'WWEE', 'WWEW', 'WWN ', 'WWNN', 'WWNS', 'WWS ', 'WWSS', 'WWSW', 'WWW ', 'WWWE', 'WWWN', 'WWWS', 'WWWW']\n",
      "pri_dir [nan, ' ', '.', '0', '1', '3', '4', '5', 'C', 'E', 'F', 'N', 'S', 'W']\n",
      "pri_road_dir [' ', 'E', 'N', 'NE', 'NW', 'S', 'SE', 'SW', 'W']\n"
     ]
    }
   ],
   "source": [
    "for x in data_raw:\n",
    "    if 'dir' in x:\n",
    "        values = data_raw[x].unique()\n",
    "        print (x, sorted(values, key=lambda x: (str(type(x)), x)))\n",
    "data_raw['pri_road_dir'].replace([' '], 'Z', inplace=True)\n",
    "data['pri_road_dir'] = data_raw['pri_road_dir']\n",
    "data_raw.drop(['travel_dirs', 'pri_dir', 'pri_road_dir'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frozen-beads",
   "metadata": {},
   "source": [
    "# Binary Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "introductory-thong",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intersection [0, 1]\n",
      "alcohol [0, 1]\n",
      "roadway_departure [0, 1]\n",
      "lane_departure [0, 1]\n",
      "dr_sex_1 [0, 1]\n",
      "dr_sex_2 [0, 1]\n"
     ]
    }
   ],
   "source": [
    "for x in ['intersection', 'alcohol', 'roadway_departure', 'lane_departure', 'dr_sex_1', 'dr_sex_2']:\n",
    "    data_raw[x].fillna(' ', inplace=True)\n",
    "    data_raw[x].replace([' '], data_raw[x].mode(), inplace=True)\n",
    "    data_raw[x].replace({'M':1, 'F':0, 'No':0, 'Yes':1}, inplace=True)\n",
    "    values = data_raw[x].unique()\n",
    "    print (x, sorted(values, key=lambda x: (str(type(x)), x)))  \n",
    "    data[x] = data_raw[x]\n",
    "    data_raw.drop([x], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-bankruptcy",
   "metadata": {},
   "source": [
    "# Integer Values\n",
    "- 'num_tot_inj'\n",
    "- 'num_veh'\n",
    "- 'parish_cd'\n",
    "- 'parish_cd.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "unsigned-nitrogen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_tot_inj [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 36, 37, 52, 64]\n",
      "num_veh [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 16]\n",
      "parish_cd [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64]\n",
      "parish_cd.1 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64]\n"
     ]
    }
   ],
   "source": [
    "for x in ['num_tot_inj', 'num_veh', 'parish_cd', 'parish_cd.1']:\n",
    "    data_raw[x].fillna(data_raw[x].mode(), inplace=True)\n",
    "    values = data_raw[x].unique()\n",
    "    print (x, sorted(values, key=lambda x: (str(type(x)), x)))  \n",
    "    data[x] = data_raw[x]\n",
    "    data_raw.drop([x], axis=1, inplace=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-synthetic",
   "metadata": {},
   "source": [
    "# Values to Put in Ranges\n",
    "- 'dr_age_1'\n",
    "- 'dr_age_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "signed-commercial",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22.0, 30.0]     29092\n",
      "(1.999, 22.0]    28982\n",
      "(40.0, 56.0]     28270\n",
      "(30.0, 40.0]     27890\n",
      "(56.0, 99.0]     27462\n",
      "0                18490\n",
      "Name: dr_age_1_bin, dtype: int64\n",
      "0                33099\n",
      "(1.999, 26.0]    27664\n",
      "(34.0, 45.0]     27379\n",
      "(57.0, 97.0]     24573\n",
      "(45.0, 57.0]     24222\n",
      "(26.0, 34.0]     23249\n",
      "Name: dr_age_2_bin, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for x in ['dr_age_1','dr_age_2']:\n",
    "    data_raw[x].fillna(0, inplace=True)\n",
    "    data_raw[x] = data_raw[x].astype(int)\n",
    "    data_raw.loc[(data_raw[x]>100), x] = 0\n",
    "    xbin = x + '_bin'\n",
    "    data_raw[xbin] = data_raw[x].replace(0,np.nan)    \n",
    "    data_raw[xbin] = pd.qcut(data_raw[xbin], 5, duplicates='drop').cat.add_categories(0)\n",
    "    data_raw[xbin].fillna(0, inplace=True)    \n",
    "    data[xbin] = data_raw[xbin]\n",
    "    values = data_raw[xbin].unique()\n",
    "    print (data[xbin].value_counts())\n",
    "    data_raw.drop([x, xbin], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-roulette",
   "metadata": {},
   "source": [
    "# Distance from the Road\n",
    "This one is weird.  \n",
    "\n",
    "- The units are either in feet or miles.\n",
    "- For many values the units are missing, and for others the measure is extreme. \n",
    "- I'm going to \n",
    "-- make all of the entries with missing units or negative distance zero, \n",
    "-- change all of the lengths to feet,\n",
    "-- take out the zeroes, \n",
    "-- put in ranges,\n",
    "-- and put the zeroes back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "direct-premises",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pri_measure 3 ['' 'FT' 'MI']\n",
      "0                        60888\n",
      "(-0.0009, 50.0]          25224\n",
      "(150.0, 528.0]           22264\n",
      "(2901.02, 52794720.0]    19860\n",
      "(50.0, 150.0]            15993\n",
      "(528.0, 2901.02]         15957\n",
      "Name: pri_dist_bin, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for x in ['pri_measure']:\n",
    "    data_raw[x] = data_raw[x].str.strip()\n",
    "    values = data_raw[x].unique()\n",
    "    print (x, len(values), values)\n",
    "data_raw.loc[data_raw['pri_measure'] == '', 'pri_dist'] = 0\n",
    "data_raw.loc[data_raw['pri_dist'] <= 0, 'pri_dist'] = 0\n",
    "data_raw.loc[data_raw['pri_measure'] == 'MI', 'pri_dist'] *= 5280\n",
    "\n",
    "for x in ['pri_dist']:\n",
    "    data_raw[x].fillna(0, inplace=True)\n",
    "#    data_raw[x] = data_raw[x].astype(int)\n",
    "#    data_raw.loc[(data_raw[x]>100), x] = 0\n",
    "    xbin = x + '_bin'\n",
    "    data_raw[xbin] = data_raw[x].replace(0,np.nan)    \n",
    "    data_raw[xbin] = pd.qcut(data_raw[xbin], 5, duplicates='drop').cat.add_categories(0)\n",
    "    data_raw[xbin].fillna(0, inplace=True)    \n",
    "    data[xbin] = data_raw[xbin]\n",
    "    print (data_raw[xbin].value_counts())\n",
    "    data_raw.drop([x, xbin], axis=1, inplace=True)\n",
    "data_raw.drop(['pri_measure'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-capability",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "separated-panama",
   "metadata": {},
   "source": [
    "# Alpha fields with 'Y' = 'Unknown' or 'Z' = 'Other'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-album",
   "metadata": {},
   "source": [
    "We have lots of fields where 'Y' is 'Unknown' and 'Z' is 'Other.  \n",
    "- Merge nan, blank, erroneous intergers, Y, and Z, into 'Z'. \n",
    "\n",
    "Other related Alpha fields:\n",
    "- 'crash_type' does not have a Y or Z, and I can't figure out what it means.\n",
    "- 'hwy_class' is mixed Alpha and integers, and I have no idea what it means.\n",
    "- 'contributing_factor' has two values, 'R' and 'O', and I have no idea what it means.\n",
    "- 'veh_severity' has five values, and I have no idea what it means.\n",
    "\n",
    "These fields have trailing spaces I had to remove:\n",
    "- 'f_harm_ev_cd1'\n",
    "- 'm_harm_ev_cd1'\n",
    "\n",
    "I lumped in some other fields here:\n",
    " - 'crash_type'\n",
    " - 'pri_contrib_fac_cd'\n",
    " - 'sec_pri_contrib_fac_cd'\n",
    " - 'hwy_type_cd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "radio-plumbing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_harm_ev_cd1 ['', 'A', 'AA', 'B', 'BB', 'C', 'CC', 'D', 'DD', 'E', 'EE', 'F', 'FF', 'G', 'GG', 'H', 'HH', 'I', 'II', 'J', 'JJ', 'K', 'KK', 'L', 'LL', 'M', 'MM', 'N', 'NN', 'O', 'OO', 'P', 'PP', 'Q', 'QQ', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'YY', 'Z']\n",
      "f_harm_ev_cd1 ['', 'A', 'AA', 'B', 'BB', 'C', 'CC', 'D', 'DD', 'E', 'EE', 'F', 'FF', 'G', 'GG', 'H', 'HH', 'I', 'II', 'J', 'JJ', 'K', 'KK', 'L', 'LL', 'M', 'MM', 'N', 'NN', 'O', 'OO', 'P', 'PP', 'Q', 'QQ', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'YY', 'Z']\n",
      "\n",
      "m_harm_ev_cd1 ['', 'A', 'AA', 'B', 'BB', 'C', 'CC', 'D', 'DD', 'E', 'EE', 'F', 'FF', 'G', 'GG', 'H', 'HH', 'I', 'II', 'J', 'JJ', 'K', 'KK', 'L', 'LL', 'M', 'MM', 'N', 'NN', 'O', 'OO', 'P', 'PP', 'Q', 'QQ', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'YY', 'Z']\n",
      "m_harm_ev_cd1 ['', 'A', 'AA', 'B', 'BB', 'C', 'CC', 'D', 'DD', 'E', 'EE', 'F', 'FF', 'G', 'GG', 'H', 'HH', 'I', 'II', 'J', 'JJ', 'K', 'KK', 'L', 'LL', 'M', 'MM', 'N', 'NN', 'O', 'OO', 'P', 'PP', 'Q', 'QQ', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'YY', 'Z']\n",
      "\n",
      "man_coll_cd ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'Z']\n",
      "man_coll_cd ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'Z']\n",
      "\n",
      "crash_type ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'X']\n",
      "crash_type ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'X']\n",
      "\n",
      "surf_cond_cd [' ', '1', '2', 'A', 'B', 'C', 'D', 'E', 'Y', 'Z']\n",
      "surf_cond_cd ['A', 'B', 'C', 'D', 'E', 'Z']\n",
      "\n",
      "invest_agency_cd ['A', 'B', 'C', 'Z']\n",
      "invest_agency_cd ['A', 'B', 'C', 'Z']\n",
      "\n",
      "veh_type_cd1 [' ', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'Z']\n",
      "veh_type_cd1 ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'Z']\n",
      "\n",
      "veh_type_cd2 [' ', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'Z']\n",
      "veh_type_cd2 ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'Z']\n",
      "\n",
      "road_rel_cd [' ', '1', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'Y', 'Z']\n",
      "road_rel_cd ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'Z']\n",
      "\n",
      "location_type ['A', 'B', 'C', 'D', 'E', 'F', 'H', 'Z']\n",
      "location_type ['A', 'B', 'C', 'D', 'E', 'F', 'H', 'Z']\n",
      "\n",
      "veh_severity_cd ['B', 'C', 'D', 'E', 'Y']\n",
      "veh_severity_cd ['B', 'C', 'D', 'E', 'Z']\n",
      "\n",
      "hwy_type_cd ['A', 'B', 'C', 'D', 'E', 'G']\n",
      "hwy_type_cd ['A', 'B', 'C', 'D', 'E', 'G']\n",
      "\n",
      "pri_contrib_fac_cd [' ', '1', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M']\n",
      "pri_contrib_fac_cd ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'Z']\n",
      "\n",
      "sec_contrib_fac_cd [' ', '1', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M']\n",
      "sec_contrib_fac_cd ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'Z']\n",
      "\n",
      "vision_obscure_1 [nan, ' ', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'Y', 'Z']\n",
      "vision_obscure_1 ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'Z']\n",
      "\n",
      "vision_obscure_2 [nan, ' ', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'Y', 'Z']\n",
      "vision_obscure_2 ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'Z']\n",
      "\n",
      "movement_reason_1 [nan, ' ', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Y', 'Z']\n",
      "movement_reason_1 ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Z']\n",
      "\n",
      "movement_reason_2 [nan, ' ', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Y', 'Z']\n",
      "movement_reason_2 ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Z']\n",
      "\n",
      "ped_actions_1 [nan, ' ', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'Y', 'Z']\n",
      "ped_actions_1 ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'Z']\n",
      "\n",
      "veh_lighting_1 [nan, ' ', 'A', 'B', 'C', 'D', 'Y']\n",
      "veh_lighting_1 ['A', 'B', 'C', 'D', 'Z']\n",
      "\n",
      "veh_lighting_2 [nan, ' ', 'A', 'B', 'C', 'Y']\n",
      "veh_lighting_2 ['A', 'B', 'C', 'Z']\n",
      "\n",
      "traff_cntl_cond_1 [nan, ' ', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'Y', 'Z']\n",
      "traff_cntl_cond_1 ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'Z']\n",
      "\n",
      "traff_cntl_cond_2 [nan, ' ', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'Y', 'Z']\n",
      "traff_cntl_cond_2 ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'Z']\n",
      "\n",
      "lighting_cd [' ', '1', '2', 'A', 'B', 'C', 'D', 'E', 'F', 'Y', 'Z']\n",
      "lighting_cd ['A', 'B', 'C', 'D', 'E', 'F', 'Z']\n",
      "\n",
      "dr_cond_cd1 [' ', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'Y', 'Z']\n",
      "dr_cond_cd1 ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'Z']\n",
      "\n",
      "dr_cond_cd2 [' ', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'Y', 'Z']\n",
      "dr_cond_cd2 ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'Z']\n",
      "\n",
      "veh_cond_cd1 [' ', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'Y', 'Z']\n",
      "veh_cond_cd1 ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'Z']\n",
      "\n",
      "veh_cond_cd2 [' ', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'Y', 'Z']\n",
      "veh_cond_cd2 ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'Z']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in ['f_harm_ev_cd1', 'm_harm_ev_cd1']:\n",
    "    data_raw[x] = data_raw[x].str.strip()\n",
    "\n",
    "for x in data_raw:\n",
    "    values = data_raw[x].unique()\n",
    "    if (\n",
    "        (('Y' in values or 'Z' in values) and len(values)<50)\n",
    "        or x in ['crash_type', 'pri_contrib_fac_cd', 'sec_contrib_fac_cd', 'hwy_type_cd']\n",
    "    ):\n",
    "        print (x, sorted(values, key=lambda x: (str(type(x)), x)))\n",
    "        data_raw[x].fillna('Z', inplace=True)\n",
    "        data_raw[x].replace([' ', 'Y'], 'Z', inplace=True)\n",
    "        data_raw[x] = data_raw[x].apply(lambda x: 'Z' if x.isnumeric() else x)\n",
    "        values = data_raw[x].unique()\n",
    "        print (x, sorted(values, key=lambda x: (str(type(x)), x)))\n",
    "        print ()\n",
    "        data[x] = data_raw[x]\n",
    "        data_raw.drop([x], axis=1, inplace=True)\n",
    "        \n",
    "data_raw.drop(['hwy_class', 'contributing_factor'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deluxe-assault",
   "metadata": {},
   "source": [
    "# Blank Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "charitable-corps",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in ['ped_actions_2']:\n",
    "    data_raw.drop([x], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-french",
   "metadata": {},
   "source": [
    "# Remaining Fields\n",
    "I don't know that any of these are likely to correlate.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "likely-hybrid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "route 1024\n",
      "milepoint 53808\n",
      "crash_num 160186\n",
      "prior_movements 1322\n",
      "csect 2141\n",
      "logmile 18203\n",
      "lrs_id 4788\n",
      "lrs_logmile 18093\n",
      "adt 749\n",
      "intersection_id 15037\n",
      "ORIG_LATITUDE 91540\n",
      "ORIG_LONGITUDE 87921\n",
      "DOTD_LATITUDE 127283\n",
      "DOTD_LONGITUDE 130753\n",
      "pri_hwy_num 1006\n",
      "milepost 7172\n",
      "pri_road_name 15724\n",
      "inter_road 35371\n"
     ]
    }
   ],
   "source": [
    "for x in data_raw:\n",
    "    values = data_raw[x].unique()\n",
    "    print (x, len(values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-nickel",
   "metadata": {},
   "source": [
    "# Fields in 'data' dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "recovered-lyric",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal\n",
      "crash_month\n",
      "crash_dayofweek\n",
      "crash_hour\n",
      "pri_road_dir\n",
      "intersection\n",
      "alcohol\n",
      "roadway_departure\n",
      "lane_departure\n",
      "dr_sex_1\n",
      "dr_sex_2\n",
      "num_tot_inj\n",
      "num_veh\n",
      "parish_cd\n",
      "parish_cd.1\n",
      "dr_age_1_bin\n",
      "dr_age_2_bin\n",
      "pri_dist_bin\n",
      "f_harm_ev_cd1\n",
      "m_harm_ev_cd1\n",
      "man_coll_cd\n",
      "crash_type\n",
      "surf_cond_cd\n",
      "invest_agency_cd\n",
      "veh_type_cd1\n",
      "veh_type_cd2\n",
      "road_rel_cd\n",
      "location_type\n",
      "veh_severity_cd\n",
      "hwy_type_cd\n",
      "pri_contrib_fac_cd\n",
      "sec_contrib_fac_cd\n",
      "vision_obscure_1\n",
      "vision_obscure_2\n",
      "movement_reason_1\n",
      "movement_reason_2\n",
      "ped_actions_1\n",
      "veh_lighting_1\n",
      "veh_lighting_2\n",
      "traff_cntl_cond_1\n",
      "traff_cntl_cond_2\n",
      "lighting_cd\n",
      "dr_cond_cd1\n",
      "dr_cond_cd2\n",
      "veh_cond_cd1\n",
      "veh_cond_cd2\n"
     ]
    }
   ],
   "source": [
    "for x in data:\n",
    "    print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-minutes",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-account",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-cleaning",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
