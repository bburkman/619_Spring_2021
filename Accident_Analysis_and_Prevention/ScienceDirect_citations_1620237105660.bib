@article{FARID201985,
title = {Comparative analysis of multiple techniques for developing and transferring safety performance functions},
journal = {Accident Analysis & Prevention},
volume = {122},
pages = {85-98},
year = {2019},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2018.09.024},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518306754},
author = {Ahmed Farid and Mohamed Abdel-Aty and Jaeyoung Lee},
keywords = {Safety performance functions, Transferability, Negative binomial model, Tobit model, Data mining methods, Highway safety manual},
abstract = {Safety performance functions (SPFs) are crash count prediction models that are used for identifying high crash risk locations, evaluating road safety before and after countermeasure deployment and comparing the safety of alternative site designs. The traditional method of modeling crash counts is negative binomial (NB) regression. Furthermore, the Highway Safety Manual (HSM) provides analytical tools, including NB SPFs, to assess and improve road safety. Even though the HSM’s SPFs are restricted to NB models, the road safety literature is rich with a variety of different modeling techniques. Researchers have calibrated the HSM’s SPFs to local conditions using a calibration method prescribed by the HSM. However, studies in which SPFs are developed and transferred to other localities are uncommon. In this paper, we develop and transfer rural divided multilane highway segment SPFs of Florida, Ohio, Illinois, Minnesota, California, Washington and North Carolina to each state. For every state, NB, zero-inflated NB, Poisson lognormal (PLN), regression tree, random forest (RF), boosting and Tobit models are developed. A hybrid model that coalesces the predictions of both the Tobit and the NB model is proposed and developed as well. All SPFs are transferred to each state and their predictive performances are evaluated to discern which model type is the most transferable. According to the transferability results, there is no single superior model type. However, the Tobit, RF, tree, NB and hybrid models demonstrate better predictive performances than those of the other methods in a considerably large proportion of transferred SPFs.}
}
@article{HONG2020105460,
title = {A driver behavior assessment and recommendation system for connected vehicles to produce safer driving environments through a “follow the leader” approach},
journal = {Accident Analysis & Prevention},
volume = {139},
pages = {105460},
year = {2020},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2020.105460},
url = {https://www.sciencedirect.com/science/article/pii/S0001457519307377},
author = {Zihan Hong and Ying Chen and Yang Wu},
keywords = {Driver behavior, Vehicle trajectories, Connected vehicles, Gaussian mixture model, Data mining, Recommendation system, Assessment system},
abstract = {As part of the emerging world of intelligent transportation, there is considerable interest in developing connected vehicles that are more capable of identifying and guiding individual drivers’ behavior than collecting mileage as a moving cart. The two goals of this study are (a) to build a conceptual framework for driver assessment and (b) develop recommendation systems to evaluate individual driving performance and guide driver behaviors, thus improving the network traffic conditions and individuals’ perceived safety. A safety score is defined relatively by comparing a driver’s individual pattern to a standard “safe driver” pattern. To elaborate, the proposed system adopts advanced data mining techniques to extract, identify, characterize, and display driving behavior patterns. The scoring system provides a basis of assessing individual drivers, who are then recommended to mimic a nearby “safe” driver in a connected environment. To evaluate and implement the proposed conceptual framework, an anonymous trajectory dataset collected from Pittsburgh urban area is applied to build the scoring system, which is then integrated within a virtually simulated environment. The results show that the proposed behavior assessment and recommendation system framework improves the overall performance of a connected traffic system beyond those attained through baseline connectivity principles.}
}
@article{DAS2019250,
title = {Using trajectory-level SHRP2 naturalistic driving data for investigating driver lane-keeping ability in fog: An association rules mining approach},
journal = {Accident Analysis & Prevention},
volume = {129},
pages = {250-262},
year = {2019},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2019.05.024},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518310182},
author = {Anik Das and Mohamed M. Ahmed and Ali Ghasemzadeh},
keywords = {Foggy weather conditions, Data mining techniques, Association rules mining, Lane-keeping, Naturalistic driving study, SHRP2, Limited visibility},
abstract = {The presence of fog has a significant adverse impact on driving. Reduced visibility due to fog obscures the driving environment and greatly affects driver behavior and performance. Lane-keeping ability is a lateral driver behavior that can be very crucial in run-off-road crashes under reduced visibility conditions. A number of data mining techniques have been adopted in previous studies to examine driver behavior including lane-keeping ability. This study adopted an association rules mining method, a promising data mining technique, to investigate driver lane-keeping ability in foggy weather conditions using big trajectory-level SHRP2 Naturalistic Driving Study (NDS) datasets. A total of 124 trips in fog with their corresponding 248 trips in clear weather (i.e., 2 clear trips: 1 foggy weather trip) were considered for the study. The results indicated that affected visibility was associated with poor lane-keeping performance in several rules. Furthermore, additional factors including male drivers, a higher number of lanes, the presence of horizontal curves, etc. were found to be significant factors for having a higher proportion of poor lane-keeping performance. Moreover, drivers with more miles driven last year were found to have better lane-keeping performance. The findings of this study could help transportation practitioners to select effective countermeasures for mitigating run-off-road crashes under limited visibility conditions.}
}
@article{IRANITALAB201727,
title = {Comparison of four statistical and machine learning methods for crash severity prediction},
journal = {Accident Analysis & Prevention},
volume = {108},
pages = {27-36},
year = {2017},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2017.08.008},
url = {https://www.sciencedirect.com/science/article/pii/S0001457517302865},
author = {Amirfarrokh Iranitalab and Aemal Khattak},
keywords = {Traffic crash severity prediction, Multinomial logit, Nearest neighbor classification, Support vector machines, Random forests, Crash costs},
abstract = {Crash severity prediction models enable different agencies to predict the severity of a reported crash with unknown severity or the severity of crashes that may be expected to occur sometime in the future. This paper had three main objectives: comparison of the performance of four statistical and machine learning methods including Multinomial Logit (MNL), Nearest Neighbor Classification (NNC), Support Vector Machines (SVM) and Random Forests (RF), in predicting traffic crash severity; developing a crash costs-based approach for comparison of crash severity prediction methods; and investigating the effects of data clustering methods comprising K-means Clustering (KC) and Latent Class Clustering (LCC), on the performance of crash severity prediction models. The 2012–2015 reported crash data from Nebraska, United States was obtained and two-vehicle crashes were extracted as the analysis data. The dataset was split into training/estimation (2012–2014) and validation (2015) subsets. The four prediction methods were trained/estimated using the training/estimation dataset and the correct prediction rates for each crash severity level, overall correct prediction rate and a proposed crash costs-based accuracy measure were obtained for the validation dataset. The correct prediction rates and the proposed approach showed NNC had the best prediction performance in overall and in more severe crashes. RF and SVM had the next two sufficient performances and MNL was the weakest method. Data clustering did not affect the prediction results of SVM, but KC improved the prediction performance of MNL, NNC and RF, while LCC caused improvement in MNL and RF but weakened the performance of NNC. Overall correct prediction rate had almost the exact opposite results compared to the proposed approach, showing that neglecting the crash costs can lead to misjudgment in choosing the right prediction method.}
}
@article{CABRALL201825,
title = {Validity and reliability of naturalistic driving scene categorization Judgments from crowdsourcing},
journal = {Accident Analysis & Prevention},
volume = {114},
pages = {25-33},
year = {2018},
note = {Road Safety on Five Continents 2016 - Conference in Rio de Janeiro, Brazil.},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2017.08.036},
url = {https://www.sciencedirect.com/science/article/pii/S0001457517303159},
author = {Christopher D.D. Cabrall and Zhenji Lu and Miltos Kyriakidis and Laura Manca and Chris Dijksterhuis and Riender Happee and Joost {de Winter}},
keywords = {Naturalistic driving study, Data annotation, Crowdsourcing, Validity, Reliability, Dash cam},
abstract = {A common challenge with processing naturalistic driving data is that humans may need to categorize great volumes of recorded visual information. By means of the online platform CrowdFlower, we investigated the potential of crowdsourcing to categorize driving scene features (i.e., presence of other road users, straight road segments, etc.) at greater scale than a single person or a small team of researchers would be capable of. In total, 200 workers from 46 different countries participated in 1.5days. Validity and reliability were examined, both with and without embedding researcher generated control questions via the CrowdFlower mechanism known as Gold Test Questions (GTQs). By employing GTQs, we found significantly more valid (accurate) and reliable (consistent) identification of driving scene items from external workers. Specifically, at a small scale CrowdFlower Job of 48 three-second video segments, an accuracy (i.e., relative to the ratings of a confederate researcher) of 91% on items was found with GTQs compared to 78% without. A difference in bias was found, where without GTQs, external workers returned more false positives than with GTQs. At a larger scale CrowdFlower Job making exclusive use of GTQs, 12,862 three-second video segments were released for annotation. Infeasible (and self-defeating) to check the accuracy of each at this scale, a random subset of 1012 categorizations was validated and returned similar levels of accuracy (95%). In the small scale Job, where full video segments were repeated in triplicate, the percentage of unanimous agreement on the items was found significantly more consistent when using GTQs (90%) than without them (65%). Additionally, in the larger scale Job (where a single second of a video segment was overlapped by ratings of three sequentially neighboring segments), a mean unanimity of 94% was obtained with validated-as-correct ratings and 91% with non-validated ratings. Because the video segments overlapped in full for the small scale Job, and in part for the larger scale Job, it should be noted that such reliability reported here may not be directly comparable. Nonetheless, such results are both indicative of high levels of obtained rating reliability. Overall, our results provide compelling evidence for CrowdFlower, via use of GTQs, being able to yield more accurate and consistent crowdsourced categorizations of naturalistic driving scene contents than when used without such a control mechanism. Such annotations in such short periods of time present a potentially powerful resource in driving research and driving automation development.}
}
@article{LI2018354,
title = {Identification of significant factors in fatal-injury highway crashes using genetic algorithm and neural network},
journal = {Accident Analysis & Prevention},
volume = {111},
pages = {354-363},
year = {2018},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2017.11.028},
url = {https://www.sciencedirect.com/science/article/pii/S0001457517304244},
author = {Yunjie Li and Dongfang Ma and Mengtao Zhu and Ziqiang Zeng and Yinhai Wang},
keywords = {Significant factor, Highway crash, Genetic algorithm, Neural network, Traffic safety},
abstract = {Identification of the significant factors of traffic crashes has been a primary concern of the transportation safety research community for many years. A fatal-injury crash is a comprehensive result influenced by multiple variables involved at the moment of the crash scenario, the main idea of this paper is to explore the process of significant factors identification from a multi-objective optimization (MOP) standpoint. It proposes a data-driven model which combines the Non-dominated Sorting Genetic Algorithm (NSGA-II) with the Neural Network (NN) architecture to efficiently search for optimal solutions. This paper also defines the index of Factor Significance (Fs) for quantitative evaluation of the significance of each factor. Based on a set of three year data of crash records collected from three main interstate highways in the Washington State, the proposed method reveals that the top five significant factors for a better Fatal-injury crash identification are 1) Driver Conduct, 2) Vehicle Action, 3) Roadway Surface Condition, 4) Driver Restraint and 5) Driver Age. The most sensitive factors from a spatiotemporal perspective are the Hour of Day, Most Severe Sobriety, and Roadway Characteristics. The method and results in this paper provide new insights into the injury pattern of highway crashes and may be used to improve the understanding of, prevention of, and other enforcement efforts related to injury crashes in the future.}
}
@article{OSMAN2019274,
title = {A hierarchical machine learning classification approach for secondary task identification from observed driving behavior data},
journal = {Accident Analysis & Prevention},
volume = {123},
pages = {274-281},
year = {2019},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2018.12.005},
url = {https://www.sciencedirect.com/science/article/pii/S000145751831114X},
author = {Osama A. Osman and Mustafa Hajij and Sogand Karbalaieali and Sherif Ishak},
keywords = {Distracted driving, Secondary tasks, Detection, Identification, Driving behavior, Ensemble tree, Machine learning, Accident investigations, In-vehicle systems},
abstract = {According to NHTSA, more than 3477 people (including 551 non-occupants) were killed and 391,000 were injured due to distraction-related crashes in 2015. The distracted driving epidemic has long been under research to identify its impact on driving behavior. There have been a few attempts to detect drivers’ engagement in secondary tasks from observed driving behavior. Yet, to the authors’ knowledge, not much effort has been directed to identify the types of secondary tasks from driving behavior parameters. This study proposes a bi-level hierarchical classification methodology using machine learning to identify the different types of secondary tasks drivers are engaged in using their driving behavior parameters. At the first level, drivers’ engagement in secondary tasks is detected, while at the second level, the distinct types of secondary tasks are identified. Comparative evaluation is performed between nine ensemble tree classification methods to identify three types of secondary tasks (hand-held cellphone calling, cellphone texting, and interaction with an adjacent passenger). The inputs to the models are five driving behavior parameters (speed, longitudinal acceleration, lateral acceleration, pedal position, and yaw rate) along with their standard deviations. The results showed that the overall secondary task detection accuracy ranged from 66% to 96%, except for the Decision Tree that was able to detect engagement in secondary tasks with a high accuracy of 99.8%. For the identification of secondary tasks types, the overall accuracy ranged from 55% to 79%, with the highest accuracy of 82.2% achieved by the Random Forest method. The findings of the paper show the proposed methodology promising to (1) characterize drivers’ engagement in unlawful secondary tasks (such as texting) as a counter measure to prevent crashes, and (2) alert drivers to pay attention back to the main driving task when risky changes to their driving behavior take place.}
}
@article{TANG2019226,
title = {Crash injury severity analysis using a two-layer Stacking framework},
journal = {Accident Analysis & Prevention},
volume = {122},
pages = {226-238},
year = {2019},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2018.10.016},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518308546},
author = {Jinjun Tang and Jian Liang and Chunyang Han and Zhibin Li and Helai Huang},
keywords = {Crash injury severity, Severity classification, Stacking model, Random Forests, Adaptive Boosting, Gradient Boosting Decision Tree},
abstract = {Crash injury severity analysis is useful for traffic management agency to further understand severity of crashes. A two-layer Stacking framework is proposed in this study to predict the crash injury severity: The fist layer integrates advantages of three base classification methods: RF (Random Forests), AdaBoost (Adaptive Boosting), and GBDT (Gradient Boosting Decision Tree); the second layer completes classification of crash injury severity based on a Logistic Regression model. A total of 5538 crashes were recorded at 326 freeway diverge areas. In the model calibration, several parameters including the number of trees in three base classification methods, learning rate, and regularization coefficient are optimized via a systematic grid search approach. In the model validation, the performance of the Stacking model is compared with several traditional models including the Support Vector Machine (SVM), Multi-Layer Perceptron (MLP) and Random Forests (RF) in the multi classification experiments. The prediction results show that Stacking model achieves superior performance evaluated by two indicators: accuracy and recall. Furthermore, all the factors used in severity prediction are classified into different categories according to their influence on the results, and sensitivity analysis of several significant factors is finally implemented to explore the impact of their value variation on the prediction accuracy.}
}
@article{LI2020105432,
title = {Detection of driver manual distraction via image-based hand and ear recognition},
journal = {Accident Analysis & Prevention},
volume = {137},
pages = {105432},
year = {2020},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2020.105432},
url = {https://www.sciencedirect.com/science/article/pii/S0001457519309029},
author = {Li Li and Boxuan Zhong and Clayton Hutmacher and Yulan Liang and William J. Horrey and Xu Xu},
keywords = {Driving distraction, Upper extremity kinematics, Deep learning, Computer vision, Multi-class classification},
abstract = {Driving distraction is a leading cause of fatal car accidents, and almost nine people are killed in the US each day because of distracting activities. Therefore, reducing the number of distraction-affected traffic accidents remains an imperative issue. A novel algorithm for detection of drivers’ manual distraction was proposed in this manuscript. The detection algorithm consists of two modules. The first module predicts the bounding boxes of the driver's right hand and right ear from RGB images. The second module takes the bounding boxes as input and predicts the type of distraction. 106,677 frames extracted from videos, which were collected from twenty participants in a driving simulator, were used for training (50%) and testing (50%). For distraction classification, the results indicated that the proposed framework could detect normal driving, using the touchscreen, and talking with a phone with F1-score 0.84, 0.69, 0.82, respectively. For overall distraction detection, it achieved F1-score of 0.74. The whole framework ran at 28 frames per second. The algorithm achieved comparable overall accuracy with similar research, and was more efficient than other methods. A demo video for the algorithm can be found at https://youtu.be/NKclK1bHRd4.}
}
@article{BASSO2020105436,
title = {The importance of flow composition in real-time crash prediction},
journal = {Accident Analysis & Prevention},
volume = {137},
pages = {105436},
year = {2020},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2020.105436},
url = {https://www.sciencedirect.com/science/article/pii/S0001457519308176},
author = {Franco Basso and Leonardo J. Basso and Raul Pezoa},
keywords = {Real-time crash prediction, Automatic vehicle identification, Flow composition, Support vector machines, Logistic regression},
abstract = {Previous real-time crash prediction models have scarcely used data disaggregated by vehicle type such as light, heavy and motorcycles. Thus, little effort has been made to quantify the impact of flow composition variables as crash precursors. We analyze the advantages of having access to this data by analyzing two scenarios, namely, with aggregated and disaggregated data. For each case, we build Logistics Regressions and Support Vector Machines models to predict accidents in a major urban expressway in Santiago, Chile. Our results show that having access to disaggregated data by vehicle type increases the prediction power up to 30 % providing, at the same time, much better intuition about the actual traffic conditions that may lead to accidents. These results may be useful when evaluating technology investments and developments in urban freeways.}
}
@article{YANG2018250,
title = {How to determine an optimal threshold to classify real-time crash-prone traffic conditions?},
journal = {Accident Analysis & Prevention},
volume = {117},
pages = {250-261},
year = {2018},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2018.04.022},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518301751},
author = {Kui Yang and Rongjie Yu and Xuesong Wang and Mohammed Quddus and Lifang Xue},
keywords = {Urban expressway safety management, Crash risk evaluation, Mixed logit model, Threshold selection method, Cross-entropy, Between-class variance},
abstract = {One of the proactive approaches in reducing traffic crashes is to identify hazardous traffic conditions that may lead to a traffic crash, known as real-time crash prediction. Threshold selection is one of the essential steps of real-time crash prediction. And it provides the cut-off point for the posterior probability which is used to separate potential crash warnings against normal traffic conditions, after the outcome of the probability of a crash occurring given a specific traffic condition on the basis of crash risk evaluation models. There is however a dearth of research that focuses on how to effectively determine an optimal threshold. And only when discussing the predictive performance of the models, a few studies utilized subjective methods to choose the threshold. The subjective methods cannot automatically identify the optimal thresholds in different traffic and weather conditions in real application. Thus, a theoretical method to select the threshold value is necessary for the sake of avoiding subjective judgments. The purpose of this study is to provide a theoretical method for automatically identifying the optimal threshold. Considering the random effects of variable factors across all roadway segments, the mixed logit model was utilized to develop the crash risk evaluation model and further evaluate the crash risk. Cross-entropy, between-class variance and other theories were employed and investigated to empirically identify the optimal threshold. And K-fold cross-validation was used to validate the performance of proposed threshold selection methods with the help of several evaluation criteria. The results indicate that (i) the mixed logit model can obtain a good performance; (ii) the classification performance of the threshold selected by the minimum cross-entropy method outperforms the other methods according to the criteria. This method can be well-behaved to automatically identify thresholds in crash prediction, by minimizing the cross entropy between the original dataset with continuous probability of a crash occurring and the binarized dataset after using the thresholds to separate potential crash warnings against normal traffic conditions.}
}
@article{JACOBEDENAUROIS2018118,
title = {Adapting artificial neural networks to a specific driver enhances detection and prediction of drowsiness},
journal = {Accident Analysis & Prevention},
volume = {121},
pages = {118-128},
year = {2018},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2018.08.017},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518304743},
author = {Charlotte {Jacobé de Naurois} and Christophe Bourdin and Clément Bougard and Jean-Louis Vercher},
keywords = {Monitoring, ANN, Adaptive learning, Inter-individual variability, Drowsiness},
abstract = {Monitoring car drivers for drowsiness is crucial but challenging. The high inter-individual variability observed in measurements raises questions about the accuracy of the drowsiness detection process. In this study, we sought to enhance the performance of machine learning models (Artificial Neural Networks: ANNs) by training a model with a group of drivers and then adapting it to a new individual. Twenty-one participants drove a car simulator for 110 min in a monotonous environment. We measured physiological and behavioral indicators and recorded driving behavior. These measurements, in addition to driving time and personal information, served as the ANN inputs. Two ANN-based models were used, one to detect the level of drowsiness every minute, and the other to predict, every minute, how long it would take the driver to reach a specific drowsiness level (moderately drowsy). The ANNs were trained with 20 participants and subsequently adapted using the earliest part of the data recorded from a 21st participant. Then the adapted ANNs were tested with the remaining data from this 21st participant. The same procedure was run for all 21 participants. Varying amounts of data were used to adapt the ANNs, from 1 to 30 min, Model performance was enhanced for each participant. The overall drowsiness monitoring performance of the models was enhanced by roughly 40% for prediction and 80% for detection.}
}
@article{FAVARO2018136,
title = {Autonomous vehicles’ disengagements: Trends, triggers, and regulatory limitations},
journal = {Accident Analysis & Prevention},
volume = {110},
pages = {136-148},
year = {2018},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2017.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S0001457517303822},
author = {Francesca Favarò and Sky Eurich and Nazanin Nader},
keywords = {Autonomous vehicles, Transportation safety, Autonomous technology disengagements},
abstract = {Autonomous Vehicle (AV) technology is quickly becoming a reality on US roads. Testing on public roads is currently undergoing, with many AV makers located and testing in Silicon Valley, California. The California Department of Motor Vehicles (CA DMV) currently mandates that any vehicle tested on California public roads be retrofitted to account for a back-up human driver, and that data related to disengagements of the AV technology be publicly available. Disengagements data is analyzed in this work, given the safety-critical role of AV disengagements, which require the control of the vehicle to be handed back to the human driver in a safe and timely manner. This study provides a comprehensive overview of the fragmented data obtained from AV manufacturers testing on California public roads from 2014 to 2017. Trends of disengagement reporting, associated frequencies, average mileage driven before failure, and an analysis of triggers and contributory factors are here presented. The analysis of the disengagements data also highlights several shortcomings of the current regulations. The results presented thus constitute an important starting point for improvements on the current drafts of the testing and deployment regulations for autonomous vehicles on public roads.}
}
@article{AMIRI2020105468,
title = {A comparison between Artificial Neural Network and Hybrid Intelligent Genetic Algorithm in predicting the severity of fixed object crashes among elderly drivers},
journal = {Accident Analysis & Prevention},
volume = {138},
pages = {105468},
year = {2020},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2020.105468},
url = {https://www.sciencedirect.com/science/article/pii/S0001457519314083},
author = {Amir Mohammadian Amiri and Amirhossein Sadri and Navid Nadimi and Moe Shams},
keywords = {Hybrid models, Elderly drivers, Fixed object crashes, Crash severity},
abstract = {Run-off-road (ROR) crashes have always been a major concern as this type of crash is usually associated with a considerable number of serious injury and fatal crashes. A substantial portion of ROR fatalities occur in collisions with fixed objects at the roadside. Thus, this study seeks to investigate the severity of ROR crashes where elderly drivers, aged 65 years or more, hit a fixed object. The reason why the present study investigates this issue among older drivers is that, comparing to younger drivers, this age group of drivers have different psychological and physical features. Because of these differences, they are more likely to get injured in ROR types of crashes. This paper applies two types of Artificial Intelligence (AI) techniques, including hybrid Intelligent Genetic Algorithm and Artificial Neural Network (ANN) using the crashe information of California in 2012 obtained from Highway Safety Information System (HSIS) database. Although the results showed that the developed ANN outperformed the hybrid Intelligent Genetic Algorithm, the hybrid approach was more capable of predicting high-severity crashes. This is rooted in the way the hybrid model was trained by taking advantage of the Genetic Algorithm (GA). The results also indicated that the light condition has been the most significant parameter in evaluating the level of severity associated with fixed object crashes among elderly drivers, which is followed by the existence of the right and left shoulders. Following these three contributing factors, cause of collision, Average Annual Daily Traffic (AADT), number of involved vehicles, age, road surface condition, and gender have been identified as the most important variables in the developed ANN, respectively. This helps to identify gaps and improve public safety towards improving the overall highway safety situation of older drivers.}
}
@article{SOILAN2018328,
title = {Safety assessment on pedestrian crossing environments using MLS data},
journal = {Accident Analysis & Prevention},
volume = {111},
pages = {328-337},
year = {2018},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2017.12.009},
url = {https://www.sciencedirect.com/science/article/pii/S0001457517304475},
author = {Mario Soilán and Belén Riveiro and Ana Sánchez-Rodríguez and Pedro Arias},
keywords = {Mobile laser scanning, Point cloud processing, Safety assessment, Classification, Geographic information system},
abstract = {In the framework of infrastructure analysis and maintenance in an urban environment, it is important to address the safety of every road user. This paper presents a methodology for the evaluation of several safety indicators on pedestrian crossing environments using geometric and radiometric information extracted from 3D point clouds collected by a Mobile Mapping System (MMS). The methodology is divided in four main modules which analyze the accessibility of the crossing area, the presence of traffic lights and traffic signs, and the visibility between a driver and a pedestrian on the proximities of a pedestrian crossing. The outputs of the analysis are exported to a Geographic Information System (GIS) where they are visualized and can be further processed in the context of city management. The methodology has been tested on approximately 30 pedestrian crossings in cluttered urban environments of two different cities. Results show that MMS are a valid mean to assess the safety of a specific urban environment, regarding its geometric conditions. Remarkable results are presented on traffic light classification, with a global F-score close to 95%.}
}
@article{WINKLER2018410,
title = {How to warn drivers in various safety-critical situations – Different strategies, different reactions},
journal = {Accident Analysis & Prevention},
volume = {117},
pages = {410-426},
year = {2018},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2018.01.040},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518300472},
author = {Susann Winkler and Juela Kazazi and Mark Vollrath},
keywords = {In-vehicle collision avoidance assistance, Warning strategy/specificity, Head-up display (HUD) visualization, Hazardous urban incidents, Driving simulator experiment, Driver behavior/subjective acceptance evaluation},
abstract = {Technological advances allow supporting drivers in a multitude of occasions, ranging from comfort enhancement to collision avoidance, for example through driver warnings, which are especially crucial for traffic safety. This psychological driving simulator experiment investigated how to warn drivers visually in order to prevent accidents in various safety-critical situations. Collision frequencies, driving behavior and subjective evaluations of situation criticality, warning understandability and helpfulness of sixty drivers were measured in two trials of eight scenarios each (within-subjects factors). The warning type in the head-up display (HUD) varied (between-subjects) in its strategy (attention-/reaction-oriented) and specificity (generic/specific) over four warning groups and a control group without a warning. The results show that the scenarios differed in their situation criticality and drivers adapted their reactions accordingly, which underlines the importance of testing driver assistance systems in diverse scenarios. Besides some learning effects over the trials, all warned drivers showed faster and stronger brake reactions. Some warning concepts were understood better than others, but all were accepted. Generic warnings were effective, yet the warning strategy should adapt to situation requirements and/or driver behavior. A stop symbol as reaction generic warning is recommendable for diverse kinds of use cases, leading to fast and strong reactions. However, for rather moderate driver reactions an attention generic approach with a caution symbol might be more suitable. Further research should investigate multi-stage warnings with adaptive strategies for application to various situations including other modalities and false alarms.}
}
@article{WANG2019365,
title = {A crash prediction method based on bivariate extreme value theory and video-based vehicle trajectory data},
journal = {Accident Analysis & Prevention},
volume = {123},
pages = {365-373},
year = {2019},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2018.12.013},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518304275},
author = {Chen Wang and Chengcheng Xu and Yulu Dai},
keywords = {Bivariate extreme value theory, Video-based vehicle trajectory, Traffic conflict, Crash prediction},
abstract = {Traditional statistical crash prediction models oftentimes suffer from poor data quality and require large amount of historical data. In this paper, we propose a crash prediction method based on a bivariate extreme value theory (EVT) framework, considering both drivers’ perception-reaction failure and failure to proper evasive actions. An unmanned aerial vehicle (UAV) was utilized to collect videos of ten intersections in Fengxian, China, at representative time periods. High-resolution vehicle trajectory data were extracted by a Kanade-Lucas-Tomasi (KLT) technique, based on four detailed metrics were derived including Time-to-accident (TA), Post-encroachment Time (PET), minimum Time-to-collision (mTTC), and Maximum Deceleration Rate (MaxD). TA was expected to capture the chance of perception-reaction failure, while other three metrics were used to measure the probability of failure to proper evasive actions. Univariate EVT models were applied to obtain marginal crash probability based on each metric. Bivariate EVT models were developed to obtain joint crash probability based on three pairs: TA and mTTC, TA and PET, and TA and MaxD. Thus, union crash probability within observation periods can be derived and the annual crash frequency of each intersection was predicted. The predictions were compared to actual annual crash frequencies, using multiple tests. The findings are three-folds: 1. The best conflict metrics for angle and rear-end crash predictions were different; 2. Bivariate EVT models were found to be superior to univariate models, regarding both angle and rear-end crash predictions; 3. TA appeared to be an important conflict metric that should be considered in a bivariate EVT model framework. In general, the proposed method can be considered as a promising tool for safety evaluation, when crash data are limited.}
}
@article{LI2020105345,
title = {Short-term prediction of safety and operation impacts of lane changes in oscillations with empirical vehicle trajectories},
journal = {Accident Analysis & Prevention},
volume = {135},
pages = {105345},
year = {2020},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2019.105345},
url = {https://www.sciencedirect.com/science/article/pii/S0001457519305019},
author = {Meng Li and Zhibin Li and Chengcheng Xu and Tong Liu},
keywords = {Freeway, Safety, Prediction, Machine learning, Lane change impact},
abstract = {Lane changes made during traffic oscillations on freeways largely affect traffic safety and could increase collision potentials. Predicting the impacts of lane change can help to develop optimal lane change strategies of autonomous vehicles for safety improvement. The study aims at proposing a machine learning method for the short-term prediction of lane-changing impacts (LCI) during the propagation of traffic oscillations. The empirical lane-changing trajectory records were obtained from the Next Generation Simulation (NGSIM) platform. A support vector regression (SVR) model was trained in this study to predict the LCI on the crash risks and flow change using microscopic traffic variables such as individual speed, gap and acceleration on both original lanes and target lanes. Sensitivity analyses were conducted in the SVR to quantify the contributions of correlative lane changing factors. The results showed that the trained SVR model achieved an accuracy of 72.81 % for the risk of crashes and 95.34 % in predicting the flow change. The sensitivity analysis explored the optimal speed and acceleration for the lane changer to achieve the lowest time integrated time-to-collision (TIT) value for safety maximization. Finally, we compared the LCI for motorcycles, automobiles and trucks as well as the LCI for both lane-changing directions (from left to right and from right to left). It was found that motorcycles conducted lane changes with smaller gaps and larger speed differences, which brings the highest crash risks. Passenger cars were found to be the safest when they conduct lane changes. Lane changes to the right had more negative impacts on traffic flow and crash risks.}
}
@article{SIEBERT2020105319,
title = {Detecting motorcycle helmet use with deep learning},
journal = {Accident Analysis & Prevention},
volume = {134},
pages = {105319},
year = {2020},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2019.105319},
url = {https://www.sciencedirect.com/science/article/pii/S0001457519308401},
author = {Felix Wilhelm Siebert and Hanhe Lin},
keywords = {Deep learning, Helmet use detection, Motorcycle, Road safety, Injury prevention},
abstract = {The continuous motorization of traffic has led to a sustained increase in the global number of road related fatalities and injuries. To counter this, governments are focusing on enforcing safe and law-abiding behavior in traffic. However, especially in developing countries where the motorcycle is the main form of transportation, there is a lack of comprehensive data on the safety-critical behavioral metric of motorcycle helmet use. This lack of data prohibits targeted enforcement and education campaigns which are crucial for injury prevention. Hence, we have developed an algorithm for the automated registration of motorcycle helmet usage from video data, using a deep learning approach. Based on 91,000 annotated frames of video data, collected at multiple observation sites in 7 cities across the country of Myanmar, we trained our algorithm to detect active motorcycles, the number and position of riders on the motorcycle, as well as their helmet use. An analysis of the algorithm's accuracy on an annotated test data set, and a comparison to available human-registered helmet use data reveals a high accuracy of our approach. Our algorithm registers motorcycle helmet use rates with an accuracy of −4.4% and +2.1% in comparison to a human observer, with minimal training for individual observation sites. Without observation site specific training, the accuracy of helmet use detection decreases slightly, depending on a number of factors. Our approach can be implemented in existing roadside traffic surveillance infrastructure and can facilitate targeted data-driven injury prevention campaigns with real-time speed. Implications of the proposed method, as well as measures that can further improve detection accuracy are discussed.}
}
@article{KATRAKAZAS201961,
title = {A new integrated collision risk assessment methodology for autonomous vehicles},
journal = {Accident Analysis & Prevention},
volume = {127},
pages = {61-79},
year = {2019},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2019.01.029},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518306614},
author = {Christos Katrakazas and Mohammed Quddus and Wen-Hua Chen},
abstract = {Real-time risk assessment of autonomous driving at tactical and operational levels is extremely challenging since both contextual and circumferential factors should concurrently be considered. Recent methods have started to simultaneously treat the context of the traffic environment along with vehicle dynamics. In particular, interaction-aware motion models that take inter-vehicle dependencies into account by utilizing the Bayesian interference are employed to mutually control multiple factors. However, communications between vehicles are often assumed and the developed models are required many parameters to be tuned. Consequently, they are computationally very demanding. Even in the cases where these desiderata are fulfilled, current approaches cannot cope with a large volume of sequential data from organically changing traffic scenarios, especially in highly complex operational environments such as dense urban areas with heterogeneous road users. To overcome these limitations, this paper develops a new risk assessment methodology that integrates a network-level collision estimate with a vehicle-based risk estimate in real-time under the joint framework of interaction-aware motion models and Dynamic Bayesian Networks (DBN). Following the formulation and explanation of the required functions, machine learning classifiers were utilized for the real-time network-level collision prediction and the results were then incorporated into the integrated DBN model for predicting collision probabilities in real-time. Results indicated an enhancement of the interaction-aware model by up to 10%, when traffic conditions are deemed as collision-prone. Hence, it was concluded that a well-calibrated collision prediction classifier provides a crucial hint for better risk perception by autonomous vehicles.}
}
@article{MUSSONE2017112,
title = {Analysis of factors affecting the severity of crashes in urban road intersections},
journal = {Accident Analysis & Prevention},
volume = {103},
pages = {112-122},
year = {2017},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2017.04.007},
url = {https://www.sciencedirect.com/science/article/pii/S0001457517301355},
author = {L. Mussone and M. Bassani and P. Masci},
keywords = {Urban roads, Road intersection, Crash severity level, 5-min flow, Short-term data, Back-propagation neural network, Generalized linear mixed model},
abstract = {Road crashes are events which depend on a variety of factors and which exhibit different magnitudes of outputs when evaluated with respect to the effects on road users. Despite a lot of research into the evaluation of crash likelihood and frequency, only a few works have focused exclusively on crash severity with these limited to sections of freeways and multilane highways. Hence, at present there is a large gap in knowledge on factors affecting the severity of crashes for other road categories, facilities, and scenarios. The paper deals with the identification of factors affecting crash severity level at urban road intersections. Two official crash records together with a weather database, a traffic data source with data aggregated into 5min intervals, and further information characterising the investigated urban intersections were used. Analyses were performed by using a back propagation neural network model and a generalized linear mixed model that enable the impact assessment of flow and other variables. Both methods demonstrate that flows play a role in the prediction of severity levels}
}
@article{JACOBEDENAUROIS201995,
title = {Detection and prediction of driver drowsiness using artificial neural network models},
journal = {Accident Analysis & Prevention},
volume = {126},
pages = {95-104},
year = {2019},
note = {10th International Conference on Managing Fatigue: Managing Fatigue to Improve Safety, Wellness, and Effectiveness”.},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2017.11.038},
url = {https://www.sciencedirect.com/science/article/pii/S0001457517304347},
author = {Charlotte {Jacobé de Naurois} and Christophe Bourdin and Anca Stratulat and Emmanuelle Diaz and Jean-Louis Vercher},
keywords = {Drowsiness, Prediction, Artificial neural network, Physiological measurement, Behavioral measurement, Driving performance and activity},
abstract = {Not just detecting but also predicting impairment of a car driver’s operational state is a challenge. This study aims to determine whether the standard sources of information used to detect drowsiness can also be used to predict when a given drowsiness level will be reached. Moreover, we explore whether adding data such as driving time and participant information improves the accuracy of detection and prediction of drowsiness. Twenty-one participants drove a car simulator for 110min under conditions optimized to induce drowsiness. We measured physiological and behavioral indicators such as heart rate and variability, respiration rate, head and eyelid movements (blink duration, frequency and PERCLOS) and recorded driving behavior such as time-to-lane-crossing, speed, steering wheel angle, position on the lane. Different combinations of this information were tested against the real state of the driver, namely the ground truth, as defined from video recordings via the Trained Observer Rating. Two models using artificial neural networks were developed, one to detect the degree of drowsiness every minute, and the other to predict every minute the time required to reach a particular drowsiness level (moderately drowsy). The best performance in both detection and prediction is obtained with behavioral indicators and additional information. The model can detect the drowsiness level with a mean square error of 0.22 and can predict when a given drowsiness level will be reached with a mean square error of 4.18min. This study shows that, on a controlled and very monotonous environment conducive to drowsiness in a driving simulator, the dynamics of driver impairment can be predicted.}
}
@article{TANG2020105551,
title = {Improving the transferability of the crash prediction model using the TrAdaBoost.R2 algorithm},
journal = {Accident Analysis & Prevention},
volume = {141},
pages = {105551},
year = {2020},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2020.105551},
url = {https://www.sciencedirect.com/science/article/pii/S0001457519317166},
author = {Dongjie Tang and Xiaohan Yang and Xuesong Wang},
keywords = {Crash prediction model, Transferability, TrAdaBoost.R2, Calibration factor, Negative binomial model},
abstract = {The crash prediction model is a useful tool for traffic administrators to identify significant risk factors, estimate crash frequency, and screen hazardous locations, but some jurisdictions interested in traffic safety analysis can collect only limited or low-quality data. Existing crash prediction models can be transferred if calibrated, but the current aggregate calibration method limits prediction accuracy and the disaggregate method is resource-consuming. Transfer learning is another approach to calibration that acquires knowledge from old data domains to solve problems in new data domains. An instance-based transfer learning technique, TrAdaBoost.R2, is adopted in this study since it meets the requirement of site-based crash prediction model transfer. TrAdaBoost.R2 was compared with AdaBoost.R2 using a simply pooled data set to examine the efficiency in extracting knowledge from a spatially outdated source data domain (old data domain). The target data domain (new data domain) was sampled to test the technique’s adaptability to small sample size. The calibration factor method based on a negative binomial model was employed to compare its predictive performance with that of the transfer learning technique. Mean square error was calculated to evaluate the prediction accuracy. Two cities in China, Shanghai and Guangzhou, were taken mutually as source data domain and target data domain. Results showed that the models constructed with TrAdaBoost.R2 had better prediction accuracy than the conventional calibration method. The TrAdaBoost.R2 is recommended due to its predictive performance and adaptability to small sample size. Crash prediction models are proposed to construct for peak and off-peak hours separately.}
}
@article{HOSSAIN201966,
title = {Real-time crash prediction models: State-of-the-art, design pathways and ubiquitous requirements},
journal = {Accident Analysis & Prevention},
volume = {124},
pages = {66-84},
year = {2019},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2018.12.022},
url = {https://www.sciencedirect.com/science/article/pii/S000145751831217X},
author = {Moinul Hossain and Mohamed Abdel-Aty and Mohammed A. Quddus and Yasunori Muromachi and Soumik Nafis Sadeek},
keywords = {ITS, Real-time crash prediction model, Design pathway, Universal design requirements},
abstract = {Proactive traffic safety management systems can monitor traffic conditions in real-time, identify the formation of unsafe traffic dynamics, and implement suitable interventions to bring unsafe conditions back to normal traffic situations. Recent advancements in artificial intelligence, sensor fusion and algorithms have brought about the introduction of a proactive safety management system closer to reality. The basic prerequisite for developing such a system is to have a reliable crash prediction model that takes real-time traffic data as input and evaluates their association with crash risk. Since the early 21st century, several studies have focused on developing such models. Although the idea has considerably matured over time, the endeavours have been quite discrete and fragmented at best because the fundamental aspects of the overall modelling approach substantially vary. Therefore, a number of transitional challenges have to be identified and subsequently addressed before a ubiquitous proactive safety management system can be formulated, designed and implemented in real-world scenarios. This manuscript conducts a comprehensive review of existing real-time crash prediction models with the aim of illustrating the state-of-the-art and systematically synthesizing the thoughts presented in existing studies in order to facilitate its translation from an idea into a ready to use technology. Towards that journey, it conducts a systematic review by applying various text mining methods and topic modelling. Based on the findings, this paper ascertains the development pathways followed in various studies, formulates the ubiquitous design requirements of such models from existing studies and knowledge of similar systems. Finally, this study evaluates the universality and design compatibility of existing models. This paper is, therefore, expected to serve as a one stop knowledge source for facilitating a faster transition from the idea of real-time crash prediction models to a real-world operational proactive traffic safety management system.}
}
@article{SCHLOGL2020105398,
title = {A multivariate analysis of environmental effects on road accident occurrence using a balanced bagging approach},
journal = {Accident Analysis & Prevention},
volume = {136},
pages = {105398},
year = {2020},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2019.105398},
url = {https://www.sciencedirect.com/science/article/pii/S0001457519308516},
author = {Matthias Schlögl},
keywords = {Adverse weather effects, Imbalanced data, Binary classification, Balanced bagging, Accident analysis, Road safety, Random forest, xgBoost},
abstract = {Determining and understanding the environmental factors contributing to road traffic accident occurrence is of core importance in road safety research. In this study, a methodology to obtain robust and unbiased results when modeling imbalanced, high-resolution accident data is described. Based on a data set covering the whole highway network of Austria in a fine spatial (250 m) and temporal (1 h) scale, the effects of 48 covariates on accident occurrence are analyzed, with a special emphasis on real-time weather variables obtained through meteorological re-analysis. A balanced bagging approach is employed to cope with the issue of class imbalance. By fitting different tree-based classifiers to a large number of bootstrapped training samples, ensembles of binary classification models are established. The final prediction is achieved through majority vote across each ensemble, resulting in a robust prediction with reduced variance. Findings show the merits of the proposed approach in terms of model quality and robustness of the results, consistently displaying accuracies around 80% while exhibiting sensitivities of approximately 50%. In addition to certain features related to roadway geometrics, surface condition and traffic volume, a number of weather variables are found to be of importance for predicting accident occurrence. The proposed methodological take may not only pave the way for further analyses of high-resolution road safety data including real-time information, but can also be transferred to any other imbalanced classification problem.}
}
@article{HALBERSBERG2019350,
title = {Young driver fatal motorcycle accident analysis by jointly maximizing accuracy and information},
journal = {Accident Analysis & Prevention},
volume = {129},
pages = {350-361},
year = {2019},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2019.04.016},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518304561},
author = {Dan Halbersberg and Boaz Lerner},
keywords = {Young drivers, Fatal accidents, Motorcycle, Machine learning, Information measure, Prediction, Bayesian network, Key factors},
abstract = {While young drivers (YDs) constitute ∼10% of the driver population, their fatality rate in motorcycle accidents is up to three times higher. Thus, we are interested in predicting fatal motorcycle accidents (FMAs), and in identifying their key factors and possible causes. Accurate prediction of YD FMAs from data by risk minimization using the 0/1 loss function (i.e., the ordinary classification accuracy) cannot be guaranteed because these accidents are only ∼1% of all YD motorcycle accidents, and classifiers tend to focus on the majority class of minor accidents at the expense of the minority class of fatal ones. Also, classifiers are usually uninformative (providing no information about the distribution of misclassifications), insensitive to error severity (making no distinction between misclassification of fatal accidents as severe or minor), and limited in identifying key factors. We propose to use an information measure (IM) that jointly maximizes accuracy and information and is sensitive to the error distribution and severity. Using a database of ∼3600 motorcycle accidents, a Bayesian network classifier optimized by IM predicted FMAs better than classifiers maximizing accuracy or other predictive or information measures, and identified fatal accident key factors and causal relations.}
}
@article{CHENG2018176,
title = {Freeway crash risks evaluation by variable speed limit strategy using real-world traffic flow data},
journal = {Accident Analysis & Prevention},
volume = {119},
pages = {176-187},
year = {2018},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2018.07.009},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518303075},
author = {Zeyang Cheng and Jian Lu and Yunxuan Li},
keywords = {Crash risk, Crash likelihood, Spatial-temporal perspective, Congestion, Variable speed limit, Freeways},
abstract = {The primary objective of this study is to evaluate the real-time crash risk of freeways by using real-world traffic flow data. The crash risk expressed as the potential crash likelihood is assessed under variable speed limit (VSL) and without VSL, in which both spatial correlation between different sites and temporal similarity are contained. Traffic flow data of Whitemud Drive network (WMD) in Canada is used to perform the relevant analysis, including VSL implementation analysis, traffic flow similarity analysis, crash risk and congestion analysis. Analytical results demonstrate that the average traffic flow under VSL schemes 1, 2, 3 and 4 are highly correlated from spatial-temporal perspective. The crash likelihoods and congestions under these VSL schemes are greatly improved. The best VSL control scheme, the most dangerous area and time, together with the most congested station of WMD are eventually determined. Subsequently, a t-test is employed to examine the significance of these results. t-Test results suggest that the improvement degree between crash risk and congestion under the best VSL control scheme show a difference, i.e., the best VSL control scheme can reduce the crash risk of moderate risk area more than high risk area, while it may have a larger melioration on the most congested area than the relatively uncongested area. Finally, these results are considered to have the potential reference in the mitigation of WMD traffic issues.}
}
@article{LI2020105371,
title = {Real-time crash risk prediction on arterials based on LSTM-CNN},
journal = {Accident Analysis & Prevention},
volume = {135},
pages = {105371},
year = {2020},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2019.105371},
url = {https://www.sciencedirect.com/science/article/pii/S0001457519311108},
author = {Pei Li and Mohamed Abdel-Aty and Jinghui Yuan},
keywords = {Real-time crash risk, Urban arterials, Recurrent neural network, Deep learning},
abstract = {Real-time crash risk prediction is expected to play a crucial role in preventing traffic accidents. However, most existing studies only focus on freeways rather than urban arterials. This paper proposes a real-time crash risk prediction model on arterials using a long short-term memory convolutional neural network (LSTM-CNN). This model can explicitly learn from the various features, such as traffic flow characteristics, signal timing, and weather conditions. Specifically, LSTM captures the long-term dependency while CNN extracts the time-invariant features. The synthetic minority over-sampling technique (SMOTE) is used for resampling the training dataset. Five common models are developed to compare the results with the proposed model, such as the XGBoost, Bayesian Logistics Regression, LSTM, etc. Experiments suggest that the proposed model outperforms others in terms of Area Under the Curve (AUC) value, sensitivity, and false alarm rate. The findings of this paper indicate the promising performance of using LSTM-CNN to predict real-time crash risk on arterials.}
}
@article{BAO2019239,
title = {A spatiotemporal deep learning approach for citywide short-term crash risk prediction with multi-source data},
journal = {Accident Analysis & Prevention},
volume = {122},
pages = {239-254},
year = {2019},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2018.10.015},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518303877},
author = {Jie Bao and Pan Liu and Satish V. Ukkusuri},
keywords = {Multi-source data, Spatiotemporal, Crash risk prediction, Deep learning},
abstract = {The primary objective of this study is to investigate how the deep learning approach contributes to citywide short-term crash risk prediction by leveraging multi-source datasets. This study uses data collected from Manhattan in New York City to illustrate the procedure. The following multiple datasets are collected: crash data, large-scale taxi GPS data, road network attributes, land use features, population data and weather data. A spatiotemporal convolutional long short-term memory network (STCL-Net) is proposed for predicting the citywide short-term crash risk. A total of nine prediction tasks are conducted and compared, including weekly, daily and hourly models with 8 × 3, 15 × 5 and 30 × 10 grids, respectively. The results suggest that the prediction performance of the proposed model decreases as the spatiotemporal resolution of prediction task increases. Moreover, four commonly-used econometric models, and four state-of-the-art machine-learning models are selected as benchmark methods to compare with the proposed STCL-Net for all the crash risk prediction tasks. The comparative analyses suggest that in general the proposed STCL-Net outperforms the benchmark methods for different crash risk prediction tasks in terms of higher prediction accuracy rate and lower false alarm rate. The results verify that the proposed spatiotemporal deep learning approach performs better at capturing the spatiotemporal characteristics for the citywide short-term crash risk prediction. In addition, the comparative analyses also reveal that econometric models perform better than machine-learning models in weekly crash risk prediction tasks, while they exhibit worse results than machine-learning models in daily crash risk prediction tasks. The results can potentially guide transportation safety engineers to select appropriate methods for different crash risk prediction tasks.}
}
@article{CHEN2019156,
title = {Key feature selection and risk prediction for lane-changing behaviors based on vehicles’ trajectory data},
journal = {Accident Analysis & Prevention},
volume = {129},
pages = {156-169},
year = {2019},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2019.05.017},
url = {https://www.sciencedirect.com/science/article/pii/S0001457519303860},
author = {Tianyi Chen and Xiupeng Shi and Yiik Diew Wong},
keywords = {Lane changing risk, Feature selection, Crash potential index, Resampling method, Random Forest},
abstract = {Risky lane-changing (LC) behavior of vehicles on the road has negative effects on traffic safety. This study presents a research framework for key feature selection and risk prediction of car’s LC behavior on the highway based on vehicles’ trajectory dataset. To the best of our knowledge, this is the first study that focuses on key feature selection and risk prediction for LC behavior on the highway. From the vehicles’ trajectory dataset, we extract car’s candidate features and apply fault tree analysis and k-Means clustering algorithm to determine the LC risk level based on the performance indicator of Crash Potential Index (CPI). Random Forest (RF) classifier is applied to select key features from car’s candidate features and predict LC risk level. This study also proposes a method to evaluate the resampling methods to resample the LC risk dataset in terms of fitness performance and prediction performance. The cars’ trajectory data collected from the Next Generation Simulation (NGSIM) dataset is used for framework development and verification. The sensitivity analysis of CPI indicates that the following cars in the original lane and target lane are respectively the safest and riskiest cars of the surrounding cars in an LC event. The results of resampling method evaluation show that SMOTETomek, which is less likely to be overfitting and has high prediction performance, is well suited for resampling the LC risk dataset on which RF classifier is trained. The results of key feature selection imply that the individual behaviors of the LC car and its surrounding cars in the original lane, the interactions between the LC car and its surrounding cars, and the interactions between the surrounding cars in the target lane (especially the interaction of the cars’ accelerations) are of importance to the LC risk.}
}
@article{OVIEDOTRESPALACIOS2020105412,
title = {“It is frustrating to not have control even though I know it’s not legal!”: A mixed-methods investigation on applications to prevent mobile phone use while driving},
journal = {Accident Analysis & Prevention},
volume = {137},
pages = {105412},
year = {2020},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2019.105412},
url = {https://www.sciencedirect.com/science/article/pii/S0001457519316525},
author = {Oscar Oviedo-Trespalacios and Verity Truelove and Mark King},
keywords = {Cell phone, Ergonomics, Human-machine interactions, Inattention, Driver behaviour, UX},
abstract = {Mobile phone distracted driving is a major risk factor for crashes. However, this behaviour has been increasing in recent years. Effective enforcement of mobile phone bans while driving faces several obstacles; as such, it is important to consider additional countermeasures. Applications designed to prevent distracted driving are a promising solution, yet more research is needed that examines their effectiveness in reducing dangerous phone use while driving behaviours. Additionally, these applications are voluntary in nature; therefore, an understanding of drivers’ perceptions of the applications is necessary to determine how to improve uptake. A mixed methods design was utilised to examine these factors in a comprehensive manner. A total of 40 participants used the smartphone application “Do Not Disturb While Driving” for iOS phone operating systems or “Android Auto” for Android phone operating systems for approximately one week and completed three diary entries reporting on their experience. Two questionnaires that examined phone use while driving behaviours were also administered to participants; one before and one after completing the study. The quantitative results found that engagement in 1) visual-manual, 2) cognitive-auditory and 3) music mobile phone interactions significantly decreased while using the application. Distraction engagement and mental workload while driving also significantly decreased while using the application. The qualitative results identified a number of areas of improvement that need to be addressed, e.g. activation of the application and Bluetooth connection reliability. The features that required improvement presented an obstacle for effective use of the applications, and in some cases resulted in drivers deciding to stop using the application. Positive perceptions of the application were associated with the experiences of the application functioning appropriately and activating automatically. These results show that applications designed for voluntary use to prevent mobile phone distracted driving are a promising countermeasure, although current applications require several improvements.}
}
@article{PARK201839,
title = {Real-time prediction and avoidance of secondary crashes under unexpected traffic congestion},
journal = {Accident Analysis & Prevention},
volume = {112},
pages = {39-49},
year = {2018},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2017.11.025},
url = {https://www.sciencedirect.com/science/article/pii/S0001457517304219},
author = {Hyoshin Park and Ali Haghani and Siby Samuel and Michael A. Knodler},
keywords = {Gradient boosting tree, Neural network, Variable importance, Rule extraction, Secondary incidents},
abstract = {According to the Federal Highway Administration, nonrecurring congestion contributes to nearly half of the overall congestion. Temporal disruptions impact the effective use of the complete roadway, due to speed reduction and rubbernecking resulting from primary incidents that in turn provoke secondary incidents. There is an additional reduction of discharge flow caused by secondary incident that significantly increases total delay. Therefore, it is important to sequentially predict the probability of secondary incidents and develop appropriate countermeasures to reduce the associated risk. Advanced computing techniques were used to easily understand and reliably predict secondary incident occurrences that have low sample mean and a small sample size. The likelihood of a secondary incident was sequentially predicted from the point of incident response to the eventual road clearance. The quality of predictions improved with the availability of additional information. The prediction performance of the principled Bayesian learning approach to neural networks (bnn) was compared to the Stochastic Gradient Boosted Decision Trees (gbdt). A pedagogical rule extraction approach, trepan, which extracts comprehensible rules from the neural networks, improved the ability to understand secondary incidents in a simplified manner. With an acceptable accuracy, gbdt is a useful tool that presents the relative importance of the predictor variables. Unexpected traffic congestion incurred by an incident is a dominant causative factor for the occurrence of secondary incidents at different stages of incident clearance. This symbolic description represents a series of decisions that may assist emergency operators by improving their decision-making capabilities. Analyzing causes and effects of traffic incidents helps traffic operators develop incident-specific strategic plans for prompt emergency response and clearance. Application of the model in connected vehicle environments will help drivers receive proactive corrective feedback before a crash. The proposed methodology can be used to alert drivers about potential highway conditions and may increase the drivers’ awareness of potential events when no rerouting is possible, optimal or otherwise.}
}
@article{NANDA2018115,
title = {Improving autocoding performance of rare categories in injury classification: Is more training data or filtering the solution?},
journal = {Accident Analysis & Prevention},
volume = {110},
pages = {115-127},
year = {2018},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2017.10.020},
url = {https://www.sciencedirect.com/science/article/pii/S0001457517303767},
author = {Gaurav Nanda and Kirsten Vallmuur and Mark Lehto},
keywords = {Injury autocoding, Rare categories, Text classification, Machine learning, More training data vs filtering, Human-machine systems},
abstract = {Introduction: Classical Machine Learning (ML) models have been found to assign the external-cause-of-injury codes (E-codes) based on injury narratives with good overall accuracy but often struggle with rare categories, primarily due to lack of enough training cases and heavily skewed nature of injurdata. In this paper, we have: a) studied the effect of increasing the size of training data on the prediction performance of three classical ML models: Multinomial Naïve Bayes (MNB), Support Vector Machine (SVM) and Logistic Regression (LR), and b) studied the effect of filtering based on prediction strength of LR model when the model is trained on very-small (10,000 cases) and very-large (450,000 cases) training sets.
Method
Data from Queensland Injury Surveillance Unit from years 2002–2012, which was categorized into 20 broad E-codes was used for this study. Eleven randomly chosen training sets of size ranging from 10,000 to 450,000 cases were used to train the ML models, and the prediction performance was analyzed on a prediction set of 50,150 cases. Filtering approach was tested on LR models trained on smallest and largest training datasets. Sensitivity was used as the performance measure for individual categories. Weighted average sensitivity (WAvg) and Unweighted average sensitivity (UAvg) were used as the measures of overall performance. Filtering approach was also tested for estimating category counts and was compared with approaches of summing prediction probabilities and counting direct predictions by ML model.
Results
The overall performance of all three ML models improved with increase in the size of training data. The overall sensitivities with maximum training size for LR and SVM models were similar (∼82%), and higher than MNB (76%). For all the ML models, the sensitivities of rare categories improved with increasing training data but they were considerably less than sensitivities of larger categories. With increasing training data size, LR and SVM exhibited diminishing improvement in UAvg whereas the improvement was relatively steady in case of MNB. Filtering based on prediction strength of LR model (and manual review of filtered cases) helped in improving the sensitivities of rare categories. A sizeable portion of cases still needed to be filtered even when the LR model was trained on very large training set. For estimating category counts, filtering approach provided best estimates for most E-codes and summing prediction probabilities approach provided better estimates for rare categories.
Conclusions
Increasing the size of training data alone cannot solve the problem of poor classification performance on rare categories by ML models. Filtering could be an effective strategy to improve classification performance of rare categories when large training data is not available.}
}
@article{BOHMLANDER201772,
title = {Context-aware system for pre-triggering irreversible vehicle safety actuators},
journal = {Accident Analysis & Prevention},
volume = {103},
pages = {72-84},
year = {2017},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2017.02.015},
url = {https://www.sciencedirect.com/science/article/pii/S0001457517300775},
author = {Dennis Böhmländer and Tobias Dirndorfer and Ali H. Al-Bayatti and Thomas Brandmeier},
keywords = {Context-aware system, Driver behavior, Crash severity estimation, Collision mitigation, Pre-triggering, Vehicle safety},
abstract = {New vehicle safety systems have led to a steady improvement of road safety and a reduction in the risk of suffering a major injury in vehicle accidents. A huge leap forward in the development of new vehicle safety systems are actuators that have to be activated irreversibly shortly before a collision in order to mitigate accident consequences. The triggering decision has to be based on measurements of exteroceptive sensors currently used in driver assistance systems. This paper focuses on developing a novel context-aware system designed to detect potential collisions and to trigger safety actuators even before an accident occurs. In this context, the analysis examines the information that can be collected from exteroceptive sensors (pre-crash data) to predict a certain collision and its severity to decide whether a triggering is entitled or not. A five-layer context-aware architecture is presented, that is able to collect contextual information about the vehicle environment and the actual driving state using different sensors, to perform reasoning about potential collisions, and to trigger safety functions upon that information. Accident analysis is used in a data model to represent uncertain knowledge and to perform reasoning. A simulation concept based on real accident data is introduced to evaluate the presented system concept.}
}
@article{NAUJOKS2017147,
title = {Driving performance at lateral system limits during partially automated driving},
journal = {Accident Analysis & Prevention},
volume = {108},
pages = {147-162},
year = {2017},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2017.08.027},
url = {https://www.sciencedirect.com/science/article/pii/S000145751730307X},
author = {Frederik Naujoks and Christian Purucker and Katharina Wiedemann and Alexandra Neukum and Stefan Wolter and Reid Steiger},
keywords = {Automated driving, Partial automation, Controllability, Lateral scenarios},
abstract = {This study investigated driver performance during system limits of partially automated driving. Using a motion-based driving simulator, drivers encountered different situations in which a partially automated vehicle could no longer safely keep the lateral guidance. Drivers were distracted by a non-driving related task on a touch display or driving without an additional secondary task. While driving in partially automated mode drivers could either take their hands off the steering wheel for only a short period of time (10s, so-called ‘Hands-on’ variant) or for an extended period of time (120s, so-called ‘Hands-off’ variant). When the system limit was reached (e.g., when entering a work zone with temporary lines), the lateral vehicle control by the automation was suddenly discontinued and a take-over request was issued to the drivers. Regardless of the hands-off interval and the availability of a secondary task, all drivers managed the transition to manual driving safely. No lane exceedances were observed and the situations were rated as ‘harmless’ by the drivers. The lack of difference between the hands-off intervals can be partly attributed to the fact that most of the drivers kept contact to the steering wheel, even in the hands-off condition. Although all drivers were able to control the system limits, most of them could not explain why exactly the take-over request was issued. The average helpfulness of the take-over request was rated on an intermediate level. Consequently, providing drivers with information about the reason for a system limit can be recommended.}
}
@article{SPORTILLO2018102,
title = {Get ready for automated driving using Virtual Reality},
journal = {Accident Analysis & Prevention},
volume = {118},
pages = {102-113},
year = {2018},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2018.06.003},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518302197},
author = {Daniele Sportillo and Alexis Paljic and Luciano Ojeda},
keywords = {Conditionally automated vehicles, Virtual Reality, Head-Mounted Display, Take-over request, Training},
abstract = {In conditionally automated vehicles, drivers can engage in secondary activities while traveling to their destination. However, drivers are required to appropriately respond, in a limited amount of time, to a take-over request when the system reaches its functional boundaries. Interacting with the car in the proper way from the first ride is crucial for car and road safety in general. For this reason, it is necessary to train drivers in a risk-free environment by providing them the best practice to use these complex systems. In this context, Virtual Reality (VR) systems represent a promising training and learning tool to properly familiarize drivers with the automated vehicle and allow them to interact with the novel equipment involved. In addition, Head-Mounted Display (HMD)-based VR (light VR) would allow for the easy deployment of such training systems in driving schools or car dealerships. In this study, the effectiveness of a light Virtual Reality training program for acquiring interaction skills in automated cars was investigated. The effectiveness of this training was compared to a user manual and a fixed-base simulator with respect to both objective and self-reported measures. Sixty subjects were randomly assigned to one of the systems in which they went through a training phase followed by a test drive in a high-end driving simulator. Results show that the training system affects the take-over performances. Moreover, self-reported measures indicate that the light VR training is preferred with respect to the other systems. Finally, another important outcome of this research is the evidence that VR plays a strategic role in the definition of the set of metrics for profiling proper driver interaction with the automated vehicle.}
}
@article{SMITS2019105280,
title = {Identifying risk of poor physical and mental health recovery following a road traffic crash: An industry-specific screening tool},
journal = {Accident Analysis & Prevention},
volume = {132},
pages = {105280},
year = {2019},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2019.105280},
url = {https://www.sciencedirect.com/science/article/pii/S000145751930497X},
author = {Esther Smits and Charlotte Brakenridge and Elise Gane and Jacelle Warren and Michelle Heron-Delaney and Justin Kenardy and Venerina Johnston},
keywords = {Traffic accidents, Recovery of function, Mental Health Recovery, Decision support techniques},
abstract = {This study aimed to develop an industry-specific tool to identify risk of poor physical and mental recovery following minor to moderate injuries sustained in a road traffic crash (RTC). Existing tools are often designed for implementation by health professionals rather than insurer case managers who may not have a background in health. This study is a secondary analysis of a longitudinal cohort study using data collected at 2–6 months and 24 months post-RTC. Participants were claimants (n = 254; Mean age = 50 years; 65% female) with mild-moderate injuries recruited through the common-law ‘fault-based’ compulsory third party scheme in Queensland, Australia. Sociodemographic, functional and psychological health factors were collected at baseline (2–6 months post RTC) and used as potential predictors for physical and mental health-related quality of life (Short Form 36 v2) at the 2-year follow-up. The LASSO (Least Absolute Shrinkage and Selection Operator) analysis identified six disability items (from the World Health Organization Disability Assessment Schedule 2) to predict poor physical and one item to predict poor mental health-related quality of life. Logistic regressions of these items in addition to age and gender were used to develop a screening tool. Using the tool, 90% of those at risk of poor physical and 80% of those at risk of poor mental health-related quality of life were identified correctly. To conclude, this study presents an 8-item, context-specific tool to help injury managers identify individuals at risk of poor physical and mental health recovery following mild-moderate RTC-related injuries. The tool requires validation in a new cohort and confirmation of acceptability by end-users.}
}
@article{SCHLOGL2019134,
title = {A comparison of statistical learning methods for deriving determining factors of accident occurrence from an imbalanced high resolution dataset},
journal = {Accident Analysis & Prevention},
volume = {127},
pages = {134-149},
year = {2019},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2019.02.008},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518307760},
author = {Matthias Schlögl and Rainer Stütz and Gregor Laaha and Michael Melcher},
keywords = {Statistical learning, Imbalanced data, Binary classification, Accident analysis, Road safety},
abstract = {One of the main aims of accident data analysis is to derive the determining factors associated with road traffic accident occurrence. While current studies mainly use variants of count data regression to achieve this aim, the problem can also be considered as a binary classification task, with the dichotomous target variable indicating events (accidents) and non-events (no accidents). The effects of 45 variables – describing road condition and geometry, traffic volume and regulations, weather, and accident time – are analyzed using a dataset in high temporal (1 h) and spatial (250 m) resolution, covering the whole highway network of Austria over the period of four consecutive years. A combination of synthetic minority oversampling and maximum dissimilarity undersampling is used to balance the training dataset. We employ and compare a series of statistical learning techniques with respect to their predictive performance and discuss the importance of determining factors of accident occurrence from the ensemble of models. Findings substantiate that a trade-off between accuracy and sensitivity is inherent to imbalanced classification problems. Results show satisfying performance of tree-based methods which exhibit accuracies between 75% and 90% while exhibiting sensitivities between 30% and 50%. Overall, this analysis emphasizes the merits of using high-resolution data in the context of accident analysis.}
}
@article{WANG2019180,
title = {Expressway crash risk prediction using back propagation neural network: A brief investigation on safety resilience},
journal = {Accident Analysis & Prevention},
volume = {124},
pages = {180-192},
year = {2019},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2019.01.007},
url = {https://www.sciencedirect.com/science/article/pii/S0001457519300302},
author = {Junhua Wang and Yumeng Kong and Ting Fu},
keywords = {Crash risk prediction, Expressway safety, Safety critical events, Safety resilience of traffic, Back-propagation neural network, Vehicle moving violation},
abstract = {This study presents the work in predicting crash risk on expressways with consideration of both the impact of safety critical events and traffic conditions. The traffic resilience theory is introduced to learn safety problems from the standpoint of 1) considering safety critical events, such as traffic violations, as the safety disturbances, and 2) considering safety resilience as the ability of the traffic, greatly associated with traffic conditions, to resist critical events turning into crashes. The concept of safety resilience was illustrated qualitatively through simulation experiments. Aimsun microsimulation software was used to simulate traffic conditions with safety critical events (vehicle violations, in this paper) involved based on the geometric design of the G15 Expressway in Shanghai. Based on data from the simulation experiment, a two-staged model was developed which classifies crash risk status into three types including no-risk, low-risk and high-risk status. Modeling approach that relies on the back propagation neural network method was applied. The performance of the model in prediction was validated through the Receiver Operating Characteristic (ROC) curve test. Results indicated that the model performed well in predicting crash risks in the simulated environment. After training the model, an extra simulation experiment involving six additional tests was conducted. Results show that the traffic resilience theory may work in explaining the relationship between traffic conditions, safety critical events and crash risk, which are the key elements in road safety field. The introduction of safety resilience may inspire further exploration on this topic in both research and practice. Meanwhile, the model can be used to predict and monitor risks on expressways in a potentially more precise way.}
}
@article{WEI2019324,
title = {Trajectory-based identification of critical instantaneous decision events at mixed-flow signalized intersections},
journal = {Accident Analysis & Prevention},
volume = {123},
pages = {324-335},
year = {2019},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2018.11.019},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518303968},
author = {Yanning Wei and Keping Li and Keshuang Tang},
keywords = {Critical instantaneous decision events, Trajectory data, Permutation entropy, Cube searching algorithm, Mixed-flow intersections},
abstract = {Mixed-flow intersections are prevailing in many developing countries such as China and India. At mixed-flow intersections, there is no clear lane discipline or regular trajectories within the intersection, especially for the non-motorized traffic. This leads to more interactions and encounters between the motorized traffic and the non-motorized traffic. Hence, critical instantaneous decision events such as abrupt accelerating, decelerating, jerking, swerving, and swinging, may occur more frequently, which result in potential traffic conflicts and crashes. This study presents a methodology to identify critical instantaneous decision events at the mixed-flow signalized intersections, based on the entropy theory and high-resolution vehicle trajectory data. A three-dimensional cube searching algorithm is firstly proposed to extract general traffic events by examining the proximity between trajectories. A novel model incorporating vehicle kinematics and Permutation Entropy is then developed to identify critical events, by quantifying driving volatility based on the time-serial trajectory data. Next, 3, 349 vehicle trajectories and 805 bicycle trajectories with a resolution of 0.12 s collected at a signalized intersection in Shanghai are used to demonstrate the proposed method. Results show that the proposed method is capable of identifying critical instantaneous decision events, and tends to produce a higher identification ratio comparing with the conventional method solely based on kinematic thresholds. A sensitivity analysis is also conducted to investigate the effects of model parameters on the performance of the proposed method. The presented work could be applied for traffic safety assessment, real-time driving alert systems, and early diagnosis of risk-prone road users at mixed-flow intersections.}
}
@article{BAO2018281,
title = {Understanding the effects of trip patterns on spatially aggregated crashes with large-scale taxi GPS data},
journal = {Accident Analysis & Prevention},
volume = {120},
pages = {281-294},
year = {2018},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2018.08.014},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518304779},
author = {Jie Bao and Pan Liu and Xiao Qin and Huaguo Zhou},
keywords = {Big data, Trip pattern, Taxi GPS data, Spatial analysis, Crashes},
abstract = {The primary objective of this study was to investigate how trip pattern variables extracted from large-scale taxi GPS data contribute to the spatially aggregated crashes in urban areas. The following five types of data were collected: crash data, large-scale taxi GPS data, road network attributes, land use features and social-demographic data. A data-driven modeling approach based on Latent Dirichlet Allocation (LDA) was proposed for discovering hidden trip patterns from a taxi GPS dataset, and a total of fifty trip patterns were identified. The collected data and the identified trip patterns were further aggregated into167 ZIP Code Tabulation Areas (ZCTA). Random forest technique was used to identify the factors that contributed to total, PDO and fatal-plus-injury crashes in the selected ZCTAs during the study period. Geographically weighted Poisson regression (GWPR) models were then developed to establish a relationship between the crashes and the contributing factors selected by the random forest technique. Comparative analyses were conducted to compare the performance of the GWPR models that considered traditional traffic exposure variables only, trip pattern variables only, and both traditional exposure and trip pattern variables. The model specification results suggest that the trip pattern variables significantly affected the crash counts in the selected ZCTAs, and the models that considered both the traditional traffic exposure and the trip pattern variables had the best goodness-of-fit in terms of the lowest MAD and AICc values.}
}
@article{KITALI201858,
title = {Likelihood estimation of secondary crashes using Bayesian complementary log-log model},
journal = {Accident Analysis & Prevention},
volume = {119},
pages = {58-67},
year = {2018},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2018.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518302999},
author = {Angela E. Kitali and Priyanka Alluri and Thobias Sando and Henrick Haule and Emmanuel Kidando and Richard Lentz},
keywords = {Secondary crashes, Complementary log-log, Likelihood, Real-time traffic data},
abstract = {Secondary crashes (SCs) occur within the spatial and temporal impact range of a primary incident. They are non-recurring events and are major contributors to increased traffic delay, and reduced safety, particularly in urban areas. However, the limited knowledge on the nature of SCs has largely impeded their mitigation strategies. The primary objective of this study was to develop a reliable SC risk prediction model using real-time traffic flow conditions. The study data were collected on a 35-mile I-95 freeway section for three years in Jacksonville, Florida. SCs were identified based on travel speed data archived by the Bluetooth detectors. Bayesian random effect complementary log-log model was used to link the probability of SCs with real-time traffic flow characteristics, primary incident characteristics, environmental conditions, and geometric characteristics. Random forests technique was used to select the important variables. The results indicated that the following variables significantly affect the likelihood of SCs: average occupancy, incident severity, percent of lanes closed, incident type, incident clearance duration, incident impact duration, and incident occurrence time. The study results have the potential to proactively prevent SCs.}
}
@article{MCDONALD201825,
title = {A contextual and temporal algorithm for driver drowsiness detection},
journal = {Accident Analysis & Prevention},
volume = {113},
pages = {25-37},
year = {2018},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2018.01.005},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518300058},
author = {Anthony D. McDonald and John D. Lee and Chris Schwarz and Timothy L. Brown},
keywords = {Drowsiness, Detection, Dynamic Bayesian Network, Random forest, Driver safety},
abstract = {This study designs and evaluates a contextual and temporal algorithm for detecting drowsiness-related lane. The algorithm uses steering angle, pedal input, vehicle speed and acceleration as input. Speed and acceleration are used to develop a real-time measure of driving context. These measures are integrated with a Dynamic Bayesian Network that considers the time dependencies in transitions between drowsiness and awake states. The Dynamic Bayesian Network algorithm is validated with data collected from 72 participants driving the National Advanced Driving Simulator. The algorithm has a significantly lower false positive rate than PERCLOS—the current gold standard—and baseline, non-contextual, algorithms under design parameters that prioritize drowsiness detection. Under these parameters, the algorithm reduces false positive rate in highway and rural environments, which are typically problematic for vehicle-based detection algorithms. This algorithm is a promising new approach to driver impairment detection and suggests contextual factors should be considered in subsequent algorithm development processes. It may be combined with comprehensive mitigation methods to improve driving safety.}
}
@article{SCHLOGL2019136,
title = {Methodological considerations with data uncertainty in road safety analysis},
journal = {Accident Analysis & Prevention},
volume = {130},
pages = {136-150},
year = {2019},
note = {Road Safety Data Considerations},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2017.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S0001457517300519},
author = {Matthias Schlögl and Rainer Stütz},
keywords = {Uncertainty, Road safety, Accident analysis, Linear referencing, GIS},
abstract = {The analysis of potential influencing factors that affect the likelihood of road accident occurrence has been of major interest for safety researchers throughout the recent decades. Even though steady methodological progresses were made over the years, several impediments pertaining to the statistical analysis of crash data remain. While issues related to methodological approaches have been subject to constructive discussion, uncertainties inherent to the most fundamental part of any analysis have been widely neglected: data. This paper scrutinizes data from various sources that are commonly used in road safety studies with respect to their actual suitability for applications in this area. Issues related to spatial and temporal aspects of data uncertainty are pointed out and their implications for road safety analysis are discussed in detail. These general methodological considerations are exemplary illustrated with data from Austria, providing suggestions and methods how to overcome these obstacles. Considering these aspects is of major importance for expediting further advances in road safety data analysis and thus for increasing road safety.}
}
@article{ALI2020105463,
title = {Understanding the discretionary lane-changing behaviour in the connected environment},
journal = {Accident Analysis & Prevention},
volume = {137},
pages = {105463},
year = {2020},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2020.105463},
url = {https://www.sciencedirect.com/science/article/pii/S0001457519312771},
author = {Yasir Ali and Zuduo Zheng and Md. {Mazharul Haque} and Mehmet Yildirimoglu and Simon Washington},
keywords = {Lane changing, Connected vehicles, Driving simulator, Gap acceptance, Hazard-duration model},
abstract = {Discretionary lane-changing (DLC) is one of the complex driving manoeuvres that requires surrounding traffic information for efficient and safe manoeuvring. The connected environment not only provides such information but also increases situational awareness, which is useful for DLC decision-making. However, the literature is devoid of any concrete evidence of such impact of the connected environment on DLC decision-making. As such, this paper analyses the effects of the connected environment on DLC behaviour. Seventy-eight participants from a diverse background performed DLCs in randomised driving conditions using the CARRS-Q advanced driving simulator. These driving conditions are: baseline (without driving messages), connected environment with perfect communication (fully functioning and uninterrupted supply of driving messages), and connected environment with communication delay (impaired communication). Various key driving behaviour indicators are analysed and compared using a linear mixed model. To analyse the effects of the connected environment on DLC decision-making, two Generalised Estimation Equation (GEE) models are developed for gap acceptance and DLC duration. In addition, a Weibull accelerated failure time hazard-based duration model is developed to investigate the impact of the connected environment on safety associated with DLC manoeuvres. We find that drivers in the connected environment have a larger spacing, larger lead and lag gaps, a longer DLC duration, and a lower acceleration noise compared to the baseline condition. The GEE model on gap acceptance reveals that drivers tend to select relatively bigger gap sizes when the connected environment offers them the subsequent gap information. Similarly, the GEE model for DLC duration suggests that the connected environment increases DLC durations by 2.22 s and 2.11 s in perfect communication and communication delay driving conditions, respectively. Finally, the hazard-based duration model provides insights into the probability of avoiding a lane-changing collision, and indicates that the probability of a lane-changing collision is less in the connected environment driving conditions than in the baseline scenario. Overall, the connected environment improves the DLC driving behaviour and enhances traffic safety.}
}
@article{LIANG2019105,
title = {Prediction of drowsiness events in night shift workers during morning driving},
journal = {Accident Analysis & Prevention},
volume = {126},
pages = {105-114},
year = {2019},
note = {10th International Conference on Managing Fatigue: Managing Fatigue to Improve Safety, Wellness, and Effectiveness”.},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2017.11.004},
url = {https://www.sciencedirect.com/science/article/pii/S0001457517303913},
author = {Yulan Liang and William J. Horrey and Mark E. Howard and Michael L. Lee and Clare Anderson and Michael S. Shreeve and Conor S. O’Brien and Charles A. Czeisler},
keywords = {Drowsy driving, Fatigue, Predictive models, Electroencephalogram (EEG), Driving performance, Infrared oculograph},
abstract = {The morning commute home is an especially vulnerable time for workers engaged in night shift work due to the heightened risk of experiencing drowsy driving. One strategy to manage this risk is to monitor the driver’s state in real time using an in vehicle monitoring system and to alert drivers when they are becoming sleepy. The primary objective of this study is to build and evaluate predictive models for drowsiness events occurring in morning drives using a variety of physiological and performance data gathered under a real driving scenario. We used data collected from 16 night shift workers who drove an instrumented vehicle for approximately two hours on a test track on two occasions: after a night shift and after a night of rest. Drowsiness was defined by two outcome events: performance degradation (Lane-Crossing models) and electroencephalogram (EEG) characterized sleep episodes (Microsleep Models). For each outcome, we assessed the accuracy of sets of predictors, including or not including a driver factor, eyelid measures, and driving performance measures. We also compared the predictions using different time intervals relative to the events (e.g., 1-min prior to the event through 10-min prior). By examining the Area Under the receiver operating characteristic Curve (AUC), accuracy, sensitivity, and specificity of the predictive models, the results showed that the inclusion of an individual driver factor improved AUC and prediction accuracy for both outcomes. Eyelid measures improved the prediction for the Lane-Crossing models, but not for Microsleep models. Prediction performance was not changed by adding driving performance predictors or by increasing the time to the event for either outcome. The best models for both measures of drowsiness were those considering driver individual differences and eyelid measures, suggesting that these indicators should be strongly considered when predicting drowsiness events. The results of this paper can benefit the development of real-time drowsiness detection and help to manage drowsiness to avoid related motor-vehicle crashes and loss.}
}
@article{DING2018116,
title = {Non-linear effects of the built environment on automobile-involved pedestrian crash frequency: A machine learning approach},
journal = {Accident Analysis & Prevention},
volume = {112},
pages = {116-126},
year = {2018},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2017.12.026},
url = {https://www.sciencedirect.com/science/article/pii/S0001457517304724},
author = {Chuan Ding and Peng Chen and Junfeng Jiao},
keywords = {Pedestrian crash frequency, Built environment, Machine learning, Variable importance, Non-linear effects},
abstract = {Although a growing body of literature focuses on the relationship between the built environment and pedestrian crashes, limited evidence is provided about the relative importance of many built environment attributes by accounting for their mutual interaction effects and their non-linear effects on automobile-involved pedestrian crashes. This study adopts the approach of Multiple Additive Poisson Regression Trees (MAPRT) to fill such gaps using pedestrian collision data collected from Seattle, Washington. Traffic analysis zones are chosen as the analytical unit. The effects of various factors on pedestrian crash frequency investigated include characteristics the of road network, street elements, land use patterns, and traffic demand. Density and the degree of mixed land use have major effects on pedestrian crash frequency, accounting for approximately 66% of the effects in total. More importantly, some factors show clear non-linear relationships with pedestrian crash frequency, challenging the linearity assumption commonly used in existing studies which employ statistical models. With various accurately identified non-linear relationships between the built environment and pedestrian crashes, this study suggests local agencies to adopt geo-spatial differentiated policies to establish a safe walking environment. These findings, especially the effective ranges of the built environment, provide evidence to support for transport and land use planning, policy recommendations, and road safety programs.}
}
@article{TAN2017428,
title = {Development of a real-time prediction model of driver behavior at intersections using kinematic time series data},
journal = {Accident Analysis & Prevention},
volume = {106},
pages = {428-436},
year = {2017},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2017.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S0001457517302385},
author = {Yaoyuan V. Tan and Michael R. Elliott and Carol A.C. Flannagan},
keywords = {Connected driverless vehicles, Connected autonomous vehicles, Bayesian additive regression trees, Naturalistic driving data, Principal components analysis, Longitudinal prediction},
abstract = {As connected autonomous vehicles (CAVs) enter the fleet, there will be a long period when these vehicles will have to interact with human drivers. One of the challenges for CAVs is that human drivers do not communicate their decisions well. Fortunately, the kinematic behavior of a human-driven vehicle may be a good predictor of driver intent within a short time frame. We analyzed the kinematic time series data (e.g., speed) for a set of drivers making left turns at intersections to predict whether the driver would stop before executing the turn. We used principal components analysis (PCA) to generate independent dimensions that explain the variation in vehicle speed before a turn. These dimensions remained relatively consistent throughout the maneuver, allowing us to compute independent scores on these dimensions for different time windows throughout the approach to the intersection. We then linked these PCA scores to whether a driver would stop before executing a left turn using the random intercept Bayesian additive regression trees. Five more road and observable vehicle characteristics were included to enhance prediction. Our model achieved an area under the receiver operating characteristic curve (AUC) of 0.84 at 94m away from the center of an intersection and steadily increased to 0.90 by 46m away from the center of an intersection.}
}
@article{SHI2019170,
title = {A feature learning approach based on XGBoost for driving assessment and risk prediction},
journal = {Accident Analysis & Prevention},
volume = {129},
pages = {170-179},
year = {2019},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2019.05.005},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518310820},
author = {Xiupeng Shi and Yiik Diew Wong and Michael Zhi-Feng Li and Chandrasekar Palanisamy and Chen Chai},
keywords = {Driving behaviour, Feature learning, XGBoost, Risk prediction},
abstract = {This study designs a framework of feature extraction and selection, to assess vehicle driving and predict risk levels. The framework integrates learning-based feature selection, unsupervised risk rating, and imbalanced data resampling. For each vehicle, about 1300 driving behaviour features are extracted from trajectory data, which produce in-depth and multi-view measures on behaviours. To estimate the risk potentials of vehicles in driving, unsupervised data labelling is proposed. Based on extracted risk indicator features, vehicles are clustered into various groups labelled with graded risk levels. Data under-sampling of the safe group is performed to reduce the risk-safe class imbalance. Afterwards, the linkages between behaviour features and corresponding risk levels are built using XGBoost, and key features are identified according to feature importance ranking and recursive elimination. The risk levels of vehicles in driving are predicted based on key features selected. As a case study, NGSIM trajectory data are used in which four risk levels are clustered by Fuzzy C-means, 64 key behaviour features are identified, and an overall accuracy of 89% is achieved for behaviour-based risk prediction. Findings show that this approach is effective and reliable to identify important features for driving assessment, and achieve an accurate prediction of risk levels.}
}
@article{WINKLER2018398,
title = {Practice makes better – Learning effects of driving with a multi-stage collision warning},
journal = {Accident Analysis & Prevention},
volume = {117},
pages = {398-409},
year = {2018},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2018.01.018},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518300186},
author = {Susann Winkler and Juela Kazazi and Mark Vollrath},
keywords = {Multi-stage collision avoidance assistance, Driving simulator experiment, Driver behavior/subjective rating, Safety-critical situations, Repeated event exposure, Head-up display (HUD) visualization},
abstract = {Advanced driver assistance systems like (forward) collision warnings can increase traffic safety. As safety-critical situations (especially in urban traffic) can be diverse, integrated adaptive systems (such as multi-stage warnings) need to be developed and examined in a variety of use cases over time instead of the more common approach of testing only one-time effectiveness in the most relevant use case. Thus, this driving simulator experiment investigated a multi-stage collision warning in partially repetitive trials (T) of various safety-critical situations (scenarios confronting drivers with hazards in form of pedestrians, obstacles or preceding vehicles). Its output adapted according to the drivers’ behavior in two warning stages (W1 – warning for moderate deceleration in less critical situations; W2 – urgent warning for strong, fast braking in more critical situations). To analyze how much drivers benefit from the assistance when allowed practice with it, the driving behavior and subjective ratings of 24 participants were measured over four trials. They comprised a baseline without assistance (T1) and three further trials with assistance – a learning phase repeating the scenarios from T1 twice (T2 + T3) and a concluding transfer drive with new scenarios (T4). As expected, the situation criticality in the urgent warning (W2) scenarios was rated higher than in the warning (W1) scenarios. While the brake reaction time differed more between the W1 scenarios, the applied brake force differed more between the W2 scenarios. However, the scenario factor often interacted with the trial factor. Since in later warning stages reaction time reductions become finite, the reaction strength gains importance. Overall the drivers benefited from the assistance. Both warning stages led to faster brake reactions (of similar strength) in all three assisted trials compared to the baseline, which additionally improved successively over time (T1–T3, T1 vs. T4, T2 vs. T4). Moreover, the drivers applied the gained knowledge from the learning phase to various new situations (transfer: faster brake reactions in T4 compared to T1 or T2). The well accepted and positively rated (helpful and understandable) two-stage collision warning can thus be recommended as it facilitates accident mitigation by earlier decelerations. Practice with advanced driver assistance systems (even in driving simulators) should be endorsed to maximize their benefits for traffic safety and accident prevention.}
}
@article{ZHOU2019105256,
title = {Analysis of commercial truck drivers’ potentially dangerous driving behaviors based on 11-month digital tachograph data and multilevel modeling approach},
journal = {Accident Analysis & Prevention},
volume = {132},
pages = {105256},
year = {2019},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2019.105256},
url = {https://www.sciencedirect.com/science/article/pii/S0001457519304737},
author = {Tuqiang Zhou and Junyi Zhang},
keywords = {Truck driver, Digital tachograph data, Driving behavior, PCA, DBSCAN, Multilevel modeling},
abstract = {This study analyzed the potentially dangerous driving behaviors of commercial truck drivers from both macro and micro perspectives. The analysis was based on digital tachograph data collected over an 11-month period and comprising 4373 trips made by 70 truck drivers. First, different types of truck drivers were identified using principal component analysis (PCA) and a density-based spatial clustering of applications with noise (DBSCAN) at the macro level. Then, a multilevel model was built to extract the variation properties of speeding behavior at the micro level. Results showed that 40% of the truck drivers tended to drive in a substantially dangerous way and the explained variance proportion of potentially extremely dangerous truck drivers (79.76%) was distinctly higher than that of other types of truck drivers (14.70%˜34.17%). This paper presents a systematic approach to extracting and examining information from a big data source of digital tachograph data. The derived findings make valuable contributions to the development of safety education programs, regulations, and proactive road safety countermeasures and management.}
}
@article{FORMOSA2020105429,
title = {Predicting real-time traffic conflicts using deep learning},
journal = {Accident Analysis & Prevention},
volume = {136},
pages = {105429},
year = {2020},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2019.105429},
url = {https://www.sciencedirect.com/science/article/pii/S000145751930973X},
author = {Nicolette Formosa and Mohammed Quddus and Stephen Ison and Mohamed Abdel-Aty and Jinghui Yuan},
keywords = {Safety Surrogate Measures, traffic conflicts, data integration architecture, Regional–Convolution Neural Network (R-CNN), Deep Neural Network (DNN)},
abstract = {Recently, technologies for predicting traffic conflicts in real-time have been gaining momentum due to their proactive nature of application and the growing implementation of ADAS technology in intelligent vehicles. In ADAS, machine learning classifiers are utilised to predict potential traffic conflicts by analysing data from in-vehicle sensors. In most cases, a condition is classified as a traffic conflict when a safety surrogate (e.g. time-to-collision, TTC) crosses a pre-defined threshold. This approach, however, largely ignores other factors that influence traffic conflicts such as speed variance, traffic density, speed and weather conditions. Considering all these factors in detecting traffic conflicts is rather complex as it requires an integration and mining of heterodox data, the unavailability of traffic conflicts and conflict prediction models capable of extracting meaningful and accurate information in a timely manner. In addition, the model has to effectively handle large imbalanced data. To overcome these limitations, this paper presents a centralised digital architecture and employs a Deep Learning methodology to predict traffic conflicts. Highly disaggregated traffic data and in-vehicle sensors data from an instrumented vehicle are collected from a section of the UK M1 motorway to build the model. Traffic conflicts are identified by a Regional–Convolution Neural Network (R-CNN) model which detects lane markings and tracks vehicles from images captured by a single front-facing camera. This data is then integrated with traffic variables and calculated safety surrogate measures (SSMs) via a centralised digital architecture to develop a series of Deep Neural Network (DNN) models to predict these traffic conflicts. The results indicate that TTC, as expected, varies by speed, weather and traffic density and the best DNN model provides an accuracy of 94% making it reliable to employ in ADAS technology as proactive safety management strategies. Furthermore, by exchanging this traffic conflict awareness data, connected vehicles (CVs) can mitigate the risk of traffic collisions.}
}
@article{JEONG2018250,
title = {Classification of motor vehicle crash injury severity: A hybrid approach for imbalanced data},
journal = {Accident Analysis & Prevention},
volume = {120},
pages = {250-261},
year = {2018},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2018.08.025},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518305232},
author = {Heejin Jeong and Youngchan Jang and Patrick J. Bowman and Neda Masoud},
keywords = {Vehicle crashes, Injury severity classification, Imbalanced data, Machine learning, Data analytics, Automated vehicle safety},
abstract = {This study aims to classify the injury severity in motor-vehicle crashes with both high accuracy and sensitivity rates. The dataset used in this study contains 297,113 vehicle crashes, obtained from the Michigan Traffic Crash Facts (MTCF) dataset, from 2016–2017. Similar to any other crash dataset, different accident severity classes are not equally represented in MTCF. To account for the imbalanced classes, several techniques have been used, including under-sampling and over-sampling. Using five classification learning models (i.e., Logistic regression, Decision tree, Neural network, Gradient boosting model, and Naïve Bayes classifier), we classify the levels of injury severity and attempt to improve the classification performance by two training-testing methods including Bootstrap aggregation (or bagging) and majority voting. Furthermore, due to the imbalance present in the dataset, we use the geometric mean (G-mean) to evaluate the classification performance. We show that the classification performance is the highest when bagging is used with decision trees, with over-sampling treatment for imbalanced data. The effect of treatments for the imbalanced data is maximized when under-sampling is combined with bagging. In addition to the original five classes of injury severity in the MTCF dataset, we consider two additional classification problems, one with two classes and the other with three classes, to (1) investigate the impact of the number of classes on the performance of classification models, and (2) enable comparing our results with the literature.}
}
@article{WANG201944,
title = {Exploring causes and effects of automated vehicle disengagement using statistical modeling and classification tree based on field test data},
journal = {Accident Analysis & Prevention},
volume = {129},
pages = {44-54},
year = {2019},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2019.04.015},
url = {https://www.sciencedirect.com/science/article/pii/S0001457519300016},
author = {Song Wang and Zhixia Li},
keywords = {Automated vehicles, Automated driving, Disengagement, Human factor, Transportation safety},
abstract = {Automated vehicles (AV) testing on the public roads is ongoing in several states in the US as well as in Europe and Asia. As long as the automated vehicle technology has not achieved full automation (Level 5), human drivers are still expected to take over the steering wheel and throttles when there is an automated vehicle disengagement. However, contributing factors and the mechanism about automated vehicle-initiated disengagement has not been quantitatively and comprehensively explored and investigated due to the lack of field test data. Besides, understanding human drivers’ perception and promptness of reaction to the AV disengagement is essential to ensure safety transition between automated and manual driving. By harnessing California’s Autonomous Vehicle Disengagement Report Database, which includes the AV disengagement data from field tests in 2016–2017, this paper quantitatively investigated the AV disengagement using multiple statistical modeling approaches that involve statistical modeling and classification tree. Specifically, the paper identifies the contributing factors impacting human drivers’ promptness to AV disengagements, and quantitatively investigates the underlying causes to AV disengagements. Results indicate that current AV disengagement on public roads is dominated by causes due to a planning issue. The cause of an AV disengagement is significantly induced by lacking certain numbers of radar and LiDAR sensors installed on the automated vehicles. These thresholds of these sensors needed are revealed. Cause of disengagement and roadway characteristics significantly impact drivers’ take-over time when facing an AV disengagement. AV perception or control issue-based disengagement can significantly extend drivers’ perception-reaction time to take over the driving. The quantitative knowledge obtained ultimately facilitates revealing the mechanisms of the automated vehicle disengagements to ensure safe AV operations on public roads.}
}
@article{YANG201840,
title = {Methodological evolution and frontiers of identifying, modeling and preventing secondary crashes on highways},
journal = {Accident Analysis & Prevention},
volume = {117},
pages = {40-54},
year = {2018},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2018.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518301398},
author = {Hong Yang and Zhenyu Wang and Kun Xie and Kaan Ozbay and Marianna Imprialou},
keywords = {Secondary crash, Road safety, Crash prevention, Traffic incident, Connected vehicles, Highway},
abstract = {Secondary crashes (SCs) or crashes that occur within the boundaries of the impact area of prior, primary crashes are one of the incident types that frequently affect highway traffic operations and safety. Existing studies have made great efforts to explore the underlying mechanisms of SCs and relevant methodologies have been evolving over the last two decades concerning the identification, modeling, and prevention of these crashes. So far there is a lack of a detailed examination on the progress, lessons, and potential opportunities regarding existing achievements in SC-related studies. This paper provides a comprehensive investigation of the state-of-the-art approaches; examines their strengths and weaknesses; and provides guidance in exploiting new directions in SC-related research. It aims to support researchers and practitioners in understanding well-established approaches so as to further explore the frontiers. Published studies focused on SCs since 1997 have been identified, reviewed, and summarized. Key issues concentrated on the following aspects are discussed: (i) static/dynamic approaches to identify SCs; (ii) parametric/non-parametric models to analyze SC risk, and (iii) deployable countermeasures to prevent SCs. Based on the examined issues, needs, and challenges, this paper further provides insights into potential opportunities such as: (a) fusing data from multiple sources for SC identification, (b) using advanced learning algorithms for real-time SC analysis, and (c) deploying connected vehicles for SC prevention in future research. This paper contributes to the research community by providing a one-stop reference for research on secondary crashes.}
}
@article{ROQUE2018165,
title = {Improving roadside design policies for safety enhancement using hazard-based duration modeling},
journal = {Accident Analysis & Prevention},
volume = {120},
pages = {165-173},
year = {2018},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2018.08.008},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518304305},
author = {Carlos Roque and Mohammad Jalayer},
keywords = {Hazard-based duration model, Run-off-road crash, Cox model, Roadside design, Forgiving roadside},
abstract = {Roadway departure (RwD) crashes, comprising run-off-road (ROR) and cross-median/centerline head-on collisions, are one of the most lethal crash types. Nationwide, from 2014 to 2016, annual RwD crashes accounted for 53% of all motor vehicle traffic fatalities. Several factors may cause a driver leave the travel lane, including an avoidance maneuver and inattention or fatigue. Roadway and roadside geometric design features (e.g., lane widths and clear zones) play a significant role in whether human error results in a crash. In this paper, we present a hazard-based duration model to investigate the distance traveled by an errant vehicle in a run-off-road crash, the stopping hazard rates, and associated risk factors. For this study, we obtained five years' (2010–2014) of crash data related to roadway departures (i.e., overturn and fixed-object crashes) from the Federal Highway Administration's Highway Safety Information System Database. The results indicate that over 50% of the observed vehicles traveled no more than 36 ft. in a ROR crash and 25% of the observed vehicles traveled at least 78 ft. We also found that seasonal, roadway, and crash variables, along with vehicle information and driver characteristics significantly contributed to the distances traveled by errant vehicles in ROR crashes. This paper presents methodological empirical evidence that the Cox proportional-hazards model is appropriate for investigating the distances traveled by errant vehicles in ROR crashes. In addition, it also provides valuable information for traffic design and management agencies to improve roadside design policies and implementing appropriately forgiving roadsides for errant vehicles.}
}
@article{DIMITRIOU2018221,
title = {Assessing rear-end crash potential in urban locations based on vehicle-by-vehicle interactions, geometric characteristics and operational conditions},
journal = {Accident Analysis & Prevention},
volume = {118},
pages = {221-235},
year = {2018},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2018.02.024},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518300861},
author = {Loukas Dimitriou and Katerina Stylianou and Mohamed A. Abdel-Aty},
keywords = {Rear-end crashes, Crash potential, Locational analysis, Near-crash behavior, Multinomial Logit model},
abstract = {Rear-end crashes are one of the most frequently occurring crash types, especially in urban networks. An understanding of the contributing factors and their significant association with rear-end crashes is of practical importance and will help in the development of effective countermeasures. The objective of this study is to assess rear-end crash potential at a microscopic level in an urban environment, by investigating vehicle-by-vehicle interactions. To do so, several traffic parameters at the individual vehicle level have been taken into consideration, for capturing car-following characteristics and vehicle interactions, and to investigate their effect on potential rear-end crashes. In this study rear-end crash potential was estimated based on stopping distance between two consecutive vehicles, and four rear-end crash potential cases were developed. The results indicated that 66.4% of the observations were estimated as rear-end crash potentials. It was also shown that rear-end crash potential was presented when traffic flow and speed standard deviation were higher. Also, locational characteristics such as lane of travel and location in the network were found to affect drivers’ car following decisions and additionally, it was shown that speeds were lower and headways higher when Heavy Goods Vehicles lead. Finally, a model-based behavioral analysis based on Multinomial Logit regression was conducted to systematically identify the statistically significant variables in explaining rear-end risk potential. The modeling results highlighted the significance of the explanatory variables associated with rear-end crash potential, however it was shown that their effect varied among different model configurations. The outcome of the results can be of significant value for several purposes, such as real-time monitoring of risk potential, allocating enforcement units in urban networks and designing targeted proactive safety policies.}
}
@article{JIANG2020105520,
title = {A long short-term memory-based framework for crash detection on freeways with traffic data of different temporal resolutions},
journal = {Accident Analysis & Prevention},
volume = {141},
pages = {105520},
year = {2020},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2020.105520},
url = {https://www.sciencedirect.com/science/article/pii/S0001457519317713},
author = {Feifeng Jiang and Kwok Kit Richard Yuen and Eric Wai Ming Lee},
keywords = {Crash detection, Deep learning methods, Long short-term memory networks, Traffic condition, Different temporal resolutions},
abstract = {Traffic crash detection is a major component of intelligent transportation systems. It can explore inner relationships between traffic conditions and crash risk, prevent potential crashes, and improve road safety. However, there exist some limitations in current studies on crash detection: (1) The commonly used machine learning methods cannot simulate the evolving transitions of traffic conditions before crash occurrences; (2) Current models collected traffic data of only one temporal resolution, which cannot fully represent traffic trends in different time intervals. Therefore, this study proposes a Long short-term memory (LSTM) based framework considering traffic data of different temporal resolutions (LSTMDTR) for crash detection. LSTM is an effective deep learning method to capture the long-term dependency and dynamic transitions of pre-crash conditions. Three LSTM networks considering traffic data of different temporal resolutions are constructed, which can comprehensively indicate traffic variations in different time intervals. A fully-connected layer is used to combine the outputs of three LSTM networks, and a dropout layer is used to reduce overfitting and improve prediction performance. The LSTMDTR model is implemented on datasets of I880-N and I805-N in California, America. The results indicate that the LSTMDTR model can obtain satisfactory performance on crash detection, with the highest crash accuracy of 70.43 %. LSTMDTR models constructed on one freeway can be transferred to other similar freeways, with 65.12 % of crash accuracy on transferability. Compared with machine learning methods and LSTM models with one or two temporal resolutions, the LSTMDTR model has been validated to perform better on crash detection and transferability. A proper number of neurons in the LSTMDTR model should be determined in real applications considering acceptable detection performance and computation time. The dropout technique can reduce overfitting and improve the generalization ability of the LSTMDTR model, increasing crash accuracy from 64.49 % to 70.43 %.}
}
@article{SAHA2020105456,
title = {Application of the Poisson-Tweedie distribution in analyzing crash frequency data},
journal = {Accident Analysis & Prevention},
volume = {137},
pages = {105456},
year = {2020},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2020.105456},
url = {https://www.sciencedirect.com/science/article/pii/S0001457519315258},
author = {Dibakar Saha and Priyanka Alluri and Eric Dumbaugh and Albert Gan},
keywords = {Traffic safety, Poisson-Tweedie distribution, Negative binomial model, Geometric Poisson model, Poisson inverse Gaussian model, Dispersion parameter},
abstract = {This paper describes a study that applies the Poisson-Tweedie distribution in developing crash frequency models. The Poisson-Tweedie distribution offers a unified framework to model overdispersed, underdispersed, zero-inflated, spatial, and longitudinal count data, as well as multiple response variables of similar or mixed types. The form of its variance function is simple, and can be specified as the mean added to the product of dispersion and mean raised to the power P. The flexibility of the Poisson-Tweedie distribution lies in the domain of P, which includes positive real number values. Special cases of the Poisson-Tweedie distribution models include the linear form of the negative binomial (NB1) model with P equal to 1.0, the geometric Poisson (GeoP) model with P equal to 1.5, the quadratic form of the negative binomial (NB2) model with P equal to 2.0, and the Poisson Inverse Gaussian (PIG) model with P equal to 3.0. A series of models were developed in this study using the Poisson-Tweedie distribution without any restrictions on the value of the power parameter as well as with specific values of the power parameter representing NB1, GeoP, NB2, and PIG models. The effects of fixed and varying dispersion parameters (i.e., dispersion as a function of covariates) on the variance and expected crash frequency estimates were also examined. Three years (2012–2014) of crash data from urban three-leg stop-controlled intersections and urban four-leg signalized intersections in the state of Florida were used to develop the models. The Poisson-Tweedie models or the GeoP models were found to perform better when the dispersion parameter was constant or fixed. With the varying dispersion parameter, the NB2 and PIG models were found to perform better, with both performing equally well. Also, the fixed dispersion parameter values were found to be smaller in the models with a higher value of the power parameter. The variation across the models in their estimates of weight factor, expected crash frequency, and potential for safety improvement of hazardous sites based on the empirical Bayes method was also discussed.}
}
@article{ALVARO201877,
title = {Driver education: Enhancing knowledge of sleep, fatigue and risky behaviour to improve decision making in young drivers},
journal = {Accident Analysis & Prevention},
volume = {112},
pages = {77-83},
year = {2018},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2017.12.017},
url = {https://www.sciencedirect.com/science/article/pii/S0001457517304554},
author = {Pasquale K. Alvaro and Nicole M. Burnett and Gerard A. Kennedy and William Yu Xun Min and Marcus McMahon and Maree Barnes and Melinda Jackson and Mark E. Howard},
keywords = {Young drivers, Sleepiness, Sleep, Circadian rhythm, Fatigue, Driving education},
abstract = {This study assessed the impact of an education program on knowledge of sleepiness and driving behaviour in young adult drivers and their performance and behaviour during simulated night driving. Thirty-four participants (18–26 years old) were randomized to receive either a four-week education program about sleep and driving or a control condition. A series of questionnaires were administered to assess knowledge of factors affecting sleep and driving before and after the four-week education program. Participants also completed a two hour driving simulator task at 1am after 17 h of extended wakefulness to assess the impact on driving behaviour. There was an increase in circadian rhythm knowledge in the intervention group following the education program. Self-reported risky behaviour increased in the control group with no changes in other aspects of sleep knowledge. There were no significant differences in proportion of intervention and control participants who had microsleeps (p ≤ .096), stopped driving due to sleepiness (p = .107), recorded objective episodes of drowsiness (p = .455), and crashed (p = .761), although there was a trend towards more control participants having microsleeps and stopping driving. Those in the intervention group reported higher subjective sleepiness at the end of the drive [M = 6.25, SD = 3.83, t(31) = 2.15, p = .05] and were more likely to indicate that they would stop driving [M = 3.08, SD = 1.16, t(31) = 2.24, p = .04]. The education program improved some aspects of driver knowledge about sleep and safety. The results also suggested that the education program lead to an increased awareness of sleepiness. Education about sleep and driving could reduce the risk of drowsy driving and associated road trauma in young drivers, but requires evaluation in a broader sample with assessment of real world driving outcomes.}
}
@article{GOH2017122,
title = {Construction accident narrative classification: An evaluation of text mining techniques},
journal = {Accident Analysis & Prevention},
volume = {108},
pages = {122-130},
year = {2017},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2017.08.026},
url = {https://www.sciencedirect.com/science/article/pii/S0001457517303068},
author = {Yang Miang Goh and C.U. Ubeynarayana},
keywords = {Accident classification, Construction safety, Data mining, Support vector machine, Text mining},
abstract = {Learning from past accidents is fundamental to accident prevention. Thus, accident and near miss reporting are encouraged by organizations and regulators. However, for organizations managing large safety databases, the time taken to accurately classify accident and near miss narratives will be very significant. This study aims to evaluate the utility of various text mining classification techniques in classifying 1000 publicly available construction accident narratives obtained from the US OSHA website. The study evaluated six machine learning algorithms, including support vector machine (SVM), linear regression (LR), random forest (RF), k-nearest neighbor (KNN), decision tree (DT) and Naive Bayes (NB), and found that SVM produced the best performance in classifying the test set of 251 cases. Further experimentation with tokenization of the processed text and non-linear SVM were also conducted. In addition, a grid search was conducted on the hyperparameters of the SVM models. It was found that the best performing classifiers were linear SVM with unigram tokenization and radial basis function (RBF) SVM with uni-gram tokenization. In view of its relative simplicity, the linear SVM is recommended. Across the 11 labels of accident causes or types, the precision of the linear SVM ranged from 0.5 to 1, recall ranged from 0.36 to 0.9 and F1 score was between 0.45 and 0.92. The reasons for misclassification were discussed and suggestions on ways to improve the performance were provided.}
}
@article{SHIRAZI2017186,
title = {A methodology to design heuristics for model selection based on the characteristics of data: Application to investigate when the Negative Binomial Lindley (NB-L) is preferred over the Negative Binomial (NB)},
journal = {Accident Analysis & Prevention},
volume = {107},
pages = {186-194},
year = {2017},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2017.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S0001457517302373},
author = {Mohammadali Shirazi and Soma Sekhar Dhavala and Dominique Lord and Srinivas Reddy Geedipally},
keywords = {Model Selection, Heuristics, Characteristics of Data, Machine Learning, Negative Binomial, Negative Binomial Lindley},
abstract = {Safety analysts usually use post-modeling methods, such as the Goodness-of-Fit statistics or the Likelihood Ratio Test, to decide between two or more competitive distributions or models. Such metrics require all competitive distributions to be fitted to the data before any comparisons can be accomplished. Given the continuous growth in introducing new statistical distributions, choosing the best one using such post-modeling methods is not a trivial task, in addition to all theoretical or numerical issues the analyst may face during the analysis. Furthermore, and most importantly, these measures or tests do not provide any intuitions into why a specific distribution (or model) is preferred over another (Goodness-of-Logic). This paper ponders into these issues by proposing a methodology to design heuristics for Model Selection based on the characteristics of data, in terms of descriptive summary statistics, before fitting the models. The proposed methodology employs two analytic tools: (1) Monte-Carlo Simulations and (2) Machine Learning Classifiers, to design easy heuristics to predict the label of the ‘most-likely-true’ distribution for analyzing data. The proposed methodology was applied to investigate when the recently introduced Negative Binomial Lindley (NB-L) distribution is preferred over the Negative Binomial (NB) distribution. Heuristics were designed to select the ‘most-likely-true’ distribution between these two distributions, given a set of prescribed summary statistics of data. The proposed heuristics were successfully compared against classical tests for several real or observed datasets. Not only they are easy to use and do not need any post-modeling inputs, but also, using these heuristics, the analyst can attain useful information about why the NB-L is preferred over the NB - or vice versa- when modeling data.}
}
@article{ULAK20181,
title = {Multivariate random parameter Tobit modeling of crashes involving aging drivers, passengers, bicyclists, and pedestrians: Spatiotemporal variations},
journal = {Accident Analysis & Prevention},
volume = {121},
pages = {1-13},
year = {2018},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2018.08.031},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518305566},
author = {Mehmet Baran Ulak and Eren Erman Ozguven and Omer Arda Vanli and Maxim A. Dulebenets and Lisa Spainhour},
keywords = {Aging bicyclists and pedestrians, Multivariate random parameter Tobit model, Spatiotemporal variations, Crash rate difference, Population factor, Bayesian inference},
abstract = {The increase in 65 years and older population in the United States compels the investigation of the crashes involving all aging (65+) roadway users (drivers, passengers, bicyclists, and pedestrians) in order to ensure their safety. As such, the objective of this research is to provide a spatiotemporal comparative investigation of the crashes involving these aging roadway users in Florida via concurrently using the same set of predictors in order to obtain comparable findings among them. First, a new metric, namely Crash Rate Difference (CRD) approach is developed, which enables one to capture potential spatial and temporal (e.g., weekend and weekday) variations in crash rates of aging user-involved crashes. Second, a multivariate random parameter Tobit model is utilized to determine the factors that drive both the crash occurrence probability and the crash rate of 65+ roadway users, accounting for the unobserved heterogeneity. Findings show that there are statistically significant heterogeneous effects of predictors on the crash rates of different roadway users, which evidences the unobserved heterogeneity across observations. Results also indicate that the presence of facilities such as hospitals, religious facilities, or supermarkets is very influential on crash rates of 65+ roadway users, advocating that roadways around these facilities should be particularly scrutinized by road safety stakeholders. Interestingly, the effect of these facilities on crashes also differs significantly between weekdays and weekends. Moreover, the roadway segments with high crash rates vary temporally depending on whether it is a weekday or a weekend. These findings regarding the spatiotemporal variations clearly indicate the need to develop and design better traffic safety measures and plans addressing these specific roadway segments, which can be tailored to alleviate traffic safety problems for 65+ roadway users.}
}
@article{GOH201877,
title = {Factors influencing unsafe behaviors: A supervised learning approach},
journal = {Accident Analysis & Prevention},
volume = {118},
pages = {77-85},
year = {2018},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2018.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518302173},
author = {Yang Miang Goh and Chalani U. Ubeynarayana and Karen Le Xin Wong and Brian H.W. Guo},
keywords = {Theory of reasoned action, Safety behavior, Construction safety, Working at height, Machine learning},
abstract = {Despite its potential, the use of machine learning in safety studies had been limited. Considering machine learning’s advantage in predictive accuracy, this study used a supervised learning approach to evaluate the relative importance of different cognitive factors within the Theory of Reasoned Action (TRA) in influencing safety behavior. Data were collected from 80 workers in a tunnel construction project using a TRA-based questionnaire. At the same time, behavior-based safety (BBS) observation data, % unsafe behavior, was collected. Subsequently, with the TRA cognitive factors as the input attributes, six widely-used machine learning algorithms and logistic regression were used to develop models to predict % unsafe behavior. The receiver operating characteristic (ROC) curves show that decision tree provides the best prediction. It was found that intention and social norms have the biggest influence on whether a worker was observed to work safely or not. Thus, managers aiming to improve safety behaviors need to pay specific attention to social norms in the worksite. The study also showed that a TRA survey can be used to extend a BBS to facilitate more effective interventions. Lastly, the study showed that machine learning algorithms provide an alternative approach for analyzing the relationship between the cognitive factors and behavioral data.}
}
@article{NAUJOKS201828,
title = {From partial and high automation to manual driving: Relationship between non-driving related tasks, drowsiness and take-over performance},
journal = {Accident Analysis & Prevention},
volume = {121},
pages = {28-42},
year = {2018},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2018.08.018},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518303944},
author = {Frederik Naujoks and Simon Höfling and Christian Purucker and Kathrin Zeeb},
keywords = {Automated driving, Controllability, Drowsiness, Distraction},
abstract = {Background
Until the level of full vehicle automation is reached, users of vehicle automation systems will be required to take over manual control of the vehicle occasionally and stay fallback-ready to some extent during the drive. Both, drowsiness caused by inactivity and the engagement in distracting non-driving related tasks (NDRTs) such as entertainment or office work have been suggested to impair the driver’s ability to safely handle these transitions of control. Thus, it is an open question whether engagement in NDRTs will impair or improve take-over performance.
Method
In a motion-based driving simulator, 64 participants completed an automated drive that lasted either one or two hours using either a partially or highly automated driving system. In the partially automated driving condition, a warning was issued after several seconds when drivers took both hands off the steering wheel, while the highly automated driving system allowed hands-off driving permanently. Drivers were allowed to bring along their smartphones and to use them during the drive. They engaged in a wide variety of NDRTs such as reading or using social media. At the end of the session, drivers had to react to a sudden lead vehicle braking event. In the partial automation condition, there was no take-over request (TOR) to notify the drivers of the braking vehicle, while in the highly automated condition, the situation happened right after the drivers had deactivated the automation in response to a TOR. The lead time of the TOR was set at 8 s. Driver’s level of drowsiness, workload (visual, mental and motoric) from carrying out the NDRT and motivational appeal of the NDRT right before the control transition were video-coded and used to predict the outcome of the braking event (i.e., reaction and system deactivation times, minimal Time-to-collision (TTC) and self-reported criticality) with a multiple regression approach.
Results
In the partial automation condition, reaction times to the braking vehicle and situation criticality as measured by the minimum TTC could be well predicted. Main predictors for increased reaction time were drowsiness and motivational appeal of the NDRT. However, visual and mental demand associated with NDRTs did decrease reaction time, suggesting that the NDRT helped the drivers to maintain alertness during the partially automated drive. Accordingly, drowsiness and motivational appeal of the NDRT increased situation criticality, while cognitive load due to the NDRT decreased it. In the highly automated condition, however, it was not possible to predict system deactivation time (in reaction to the TOR), brake reaction time to the braking vehicle and situation criticality by observed drowsiness and NDRT engagement.
Discussion
The results suggest a relationship between the driver’s drowsiness and NDRT engagement in partial automation but not in highly automated driving. Several explanations for this finding are discussed. It could be possible that the lead time of 8 s might have given the drivers enough time to complete the driver state transition process from executing NDRTs to manual driving, putting them in a position to be able to cope with the driving event, while this was not possible in the partial automation condition. Methodological issues that might have led to a non-detection of an effect of drowsiness or NDRT engagement in the highly automated driving condition, such as the sample size and sensitivity of the observer ratings, are also discussed.}
}
@article{KITA2020105514,
title = {Differences between males and females in the prediction of smartphone use while driving: Mindfulness and income},
journal = {Accident Analysis & Prevention},
volume = {140},
pages = {105514},
year = {2020},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2020.105514},
url = {https://www.sciencedirect.com/science/article/pii/S0001457519312746},
author = {Erez Kita and Gil Luria},
keywords = {Mindfulness, Income, Biological sex, Using smartphones while driving, Young drivers},
abstract = {Introduction
This study examines the relationship between two variables–mindfulness and income–with regards to their relationship to the use of smartphones by young drivers, which has been known to increase the likelihood of car accidents, endangering young drivers and other road users. The study focuses on the relationship between these variables and the use of smartphones while driving, and how this relationship differs between males and females.
Method
The study sample included 221 young drivers who were legally permitted to drive without supervision. The subjects were first asked to complete questionnaires on mindfulness and income. Next, their smartphone use while driving was monitored over a one-month period. This study is unique as it used an objective smartphone monitoring application (rather than self-reporting) to count the number of times the young participants actually touched their smartphones while driving.
Results
The findings show that the effects of social and personal factors (i.e., income and mindfulness) on the use of smartphones while driving are significant for males but not for females.
Conclusions
Most studies that investigate differences between males and females with respect to safety focus on differences in the averages of safety-related variables (such as safety performance and outcomes). In the current study, however, we identified differences in relationships between variables and demonstrated that what predicts safety-related behavior in males may not be a good predictor for females.
Practical applications
Mindfulness and income can be used to identify male populations that are at risk of using smartphones while driving. Interventions that improve mindfulness can be used to reduce the use of smartphones by male drivers.}
}
@article{ALLIBAWY2018188,
title = {Modular design of fatigue detection in naturalistic driving environments},
journal = {Accident Analysis & Prevention},
volume = {120},
pages = {188-194},
year = {2018},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2018.08.012},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518304639},
author = {Hilal Al-libawy and Ali Al-Ataby and Waleed Al-Nuaimy and Majid A. Al-Taee},
keywords = {Bayesian combiner, Driver fatigue, Machine learning, Modular structure, Performance optimisation, Particle swarm optimisation},
abstract = {Research in driver mental fatigue is motivated by the fact that errors made by drivers often have life-threatening consequences. This paper proposes a new modular design approach for the early detection of driver fatigue system taking into account optimisation of system performance using particle swarm optimisation (PSO). The proposed system is designed and implemented using an existing dataset that was simultaneously collected from participants and vehicles in a naturalistic environment. Four types of data are considered as fatigue-related metrics including: vehicle acceleration, vehicle rotation pattern, driver's head position and driver's head rotation. The driver's blink rate data is used in this work as a proxy for ground truth for the classification algorithm. The collected data elements are initially fed to input modules represented by ternary neural network classifiers that estimates alertness. A Bayesian algorithm with PSO is then used to combine and optimise detection performance based on the number of existing input modules as well as their output states. Performance of the developed fatigue-detection system is assessed experimentally with a small data samples of driver trips. The obtained results are found in agreement with the state-of-the-art in terms of accuracy (90.4%), sensitivity (92.6%) and specificity (90.7%). These results are achieved with significant design flexibility and robustness against partial loss of input data source(s). However, due to small sample size of dataset (N = 3), a larger dataset need to be tested with the same system framework to generalise the findings of this work.}
}
@article{GUPTA2019163,
title = {Pedestrian's risk-based negotiation model for self-driving vehicles to get the right of way},
journal = {Accident Analysis & Prevention},
volume = {124},
pages = {163-173},
year = {2019},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2019.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518308716},
author = {Surabhi Gupta and Maria Vasardani and Bharat Lohani and Stephan Winter},
keywords = {Negotiation, Self-driving vehicles, Vehicle–pedestrian interaction, Traffic flow, Pedestrian risk},
abstract = {Negotiations among drivers and pedestrians are common on roads, but it is still challenging for a self-driving vehicle to negotiate for its right of way with other human road users, especially pedestrians. Currently, the self-driving vehicles are programmed for conservative behavior, yielding to approaching pedestrians. Consequently, the future urban traffic will slow down significantly. In this paper, a conceptual model of vehicle–pedestrian negotiation is proposed. This model allows individual decision making of multiple vehicles and pedestrians, extending a prior negotiation model for a single vehicle and a single pedestrian. The possible negotiation opportunities for vehicles are modeled considering different risk-taking behaviors of pedestrians. Simulation results show an overall improvement in the waiting time of vehicles and thus in the intersection throughput, compared to conservative vehicle behavior. The simulation results show also that the benefit of reduced waiting times for vehicles comes at the cost of some waiting time for pedestrians. However, the observed pedestrian waiting times in this model are not more than the generally accepted waiting times reported in empirical studies.}
}
@article{OVIEDOTRESPALACIOS2018253,
title = {Driving behaviour while self-regulating mobile phone interactions: A human-machine system approach},
journal = {Accident Analysis & Prevention},
volume = {118},
pages = {253-262},
year = {2018},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2018.03.020},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518301246},
author = {Oscar Oviedo-Trespalacios and Md Mazharul Haque and Mark King and Sebastien Demmel},
keywords = {Ergonomics, Distraction, Calling, Behavioural adaptation, Browsing, Texting},
abstract = {Mobile phone distracted driving is a recurrent issue in road safety worldwide. Recent research on driving behaviour of distracted drivers suggests that in certain circumstances drivers seem to assume safer behaviours while using a mobile phone. Despite a high volume of research on this topic, self-regulation by mobile phone distracted drivers is not well understood as many driving simulator experiments are designed to impose an equal level of distraction to participants being tested for their driving performance. The aim of this research was to investigate the relationship between self-regulatory secondary task performance and driving. By a driving simulator experiment in which participants were allowed to perform their secondary tasks whenever they feel appropriate, the driving performance of 35 drivers aged 18–29 years was observed under three phone conditions including non-distraction (no phone use), hands-free interactions and visual-manual interactions in the CARRS-Q advanced driving simulator. Drivers’ longitudinal and lateral vehicle control observed across various road traffic conditions were then modelled by Generalized Estimation Equations (GEE) with exchangeable correlation structure accounting for heterogeneity resulting from multiple observations from the same driver. Results show that the extent of engagement in the secondary task influence both longitudinal and lateral control of vehicles. Drivers who engaged in a large number of hands-free interactions are found to select lower driving speed. In contrast, longer visual-manual interactions are found to result in higher driving speed among drivers self-regulating their secondary task. Among the road traffic conditions, drivers distracted by their self-regulated secondary tasks are found to select lower speeds along the s-curve compared to straight and motorway segments. In summary, the applied human-machine system approach suggests that road traffic demands play a vital role in both secondary task management and driving performance.}
}
@article{ZIAKOPOULOS2020105323,
title = {A review of spatial approaches in road safety},
journal = {Accident Analysis & Prevention},
volume = {135},
pages = {105323},
year = {2020},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2019.105323},
url = {https://www.sciencedirect.com/science/article/pii/S0001457519309893},
author = {Apostolos Ziakopoulos and George Yannis},
keywords = {Road safety, spatial analysis, crash analysis, study characteristics, areal units},
abstract = {Spatial analyses of crashes have been adopted in road safety for decades in order to determine how crashes are affected by neighboring locations, how the influence of parameters varies spatially and which locations warrant interventions more urgently. The aim of the present research is to critically review the existing literature on different spatial approaches through which researchers handle the dimension of space in its various aspects in their studies and analyses. Specifically, the use of different areal unit levels in spatial road safety studies is investigated, different modelling approaches are discussed, and the corresponding study design characteristics are summarized in respective tables including traffic, road environment and area parameters and spatial aggregation approaches. Developments in famous issues in spatial analysis such as the boundary problem, the modifiable areal unit problem and spatial proximity structures are also discussed. Studies focusing on spatially analyzing vulnerable road users are reviewed as well. Regarding spatial models, the application, advantages and disadvantages of various functional/econometric approaches, Bayesian models and machine learning methods are discussed. Based on the reviewed studies, present challenges and future research directions are determined.}
}
@article{ROCHA2019105269,
title = {A multivariate-based variable selection framework for clustering traffic conflicts in a brazilian freeway},
journal = {Accident Analysis & Prevention},
volume = {132},
pages = {105269},
year = {2019},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2019.105269},
url = {https://www.sciencedirect.com/science/article/pii/S0001457519305330},
author = {Miriam Rocha and Michel Anzanello and Felipe Caleffi and Helena Cybis and Gabrielli Yamashita},
keywords = {Collision risk, Traffic conflicts, variable selection, Clustering, NLPCA, SOM},
abstract = {More than one million people die or suffer non-fatal injuries annually due to road accidents around the world. Understanding the causes that give rise to different types of conflict events, as well as their characteristics, can help researchers and traffic authorities to draw up strategies aimed at mitigating collision risks. This paper proposes a framework for grouping traffic conflicts relying on similar profiles and factors that contribute to conflict occurrence using self-organizing maps (SOM). In order to improve the quality of the formed groups, we developed a novel variable importance index relying on the outputs of the nonlinear principal component analysis (NLPCA) that intends to identify the most informative variables for grouping collision events. Such index guides a backward variable selection procedure in which less relevant variables are removed one-by-one; after each removal, the clustering quality is assessed via the Davies-Bouldin (DB) index. The proposed framework was applied to a real-time dataset collected from a Brazilian highway aimed at allocating traffic conflicts into groups presenting similar profiles. The selected variables suggest that lower average speeds, which are typically verified during congestion events, contribute to conflict occurrence. Higher variability on speed (denoted by high standard deviation, and speed’s coefficient of variation levels on that variable), which are also perceived in the assessed freeway near to congestion periods, also contribute to conflicts.}
}
@article{SCHWARZ201755,
title = {Augmented reality warnings in vehicles: Effects of modality and specificity on effectiveness},
journal = {Accident Analysis & Prevention},
volume = {101},
pages = {55-66},
year = {2017},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2017.01.019},
url = {https://www.sciencedirect.com/science/article/pii/S0001457517300465},
author = {Felix Schwarz and Wolfgang Fastenmeier},
keywords = {Collision avoidance, Sight obstruction, Reliability, Warning design, Specific warnings, Augmented reality, Spatial referencing, Specificity},
abstract = {In the future, vehicles will be able to warn drivers of hidden dangers before they are visible. Specific warning information about these hazards could improve drivers’ reactions and the warning effectiveness, but could also impair them, for example, by additional cognitive-processing costs. In a driving simulator study with 88 participants, we investigated the effects of modality (auditory vs. visual) and specificity (low vs. high) on warning effectiveness. For the specific warnings, we used augmented reality as an advanced technology to display the additional auditory or visual warning information. Part one of the study concentrates on the effectiveness of necessary warnings and part two on the drivers’ compliance despite false alarms. For the first warning scenario, we found several positive main effects of specificity. However, subsequent effects of specificity were moderated by the modality of the warnings. The specific visual warnings were observed to have advantages over the three other warning designs concerning gaze and braking reaction times, passing speeds and collision rates. Besides the true alarms, braking reaction times as well as subjective evaluation after these warnings were still improved despite false alarms. The specific auditory warnings were revealed to have only a few advantages, but also several disadvantages. The results further indicate that the exact coding of additional information, beyond its mere amount and modality, plays an important role. Moreover, the observed advantages of the specific visual warnings highlight the potential benefit of augmented reality coding to improve future collision warnings.}
}
@article{WANG2019160,
title = {Modeling when and where a secondary accident occurs},
journal = {Accident Analysis & Prevention},
volume = {130},
pages = {160-166},
year = {2019},
note = {Road Safety Data Considerations},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2018.01.024},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518300307},
author = {Junhua Wang and Boya Liu and Ting Fu and Shuo Liu and Joshua Stipancic},
keywords = {Secondary accident, Spatiotemporal Gap, BP neural network, LSSVM, Incident management},
abstract = {The occurrence of secondary accidents leads to traffic congestion and road safety issues. Secondary accident prevention has become a major consideration in traffic incident management. This paper investigates the location and time of a potential secondary accident after the occurrence of an initial traffic accident. With accident data and traffic loop data collected over three years from California interstate freeways, a shock wave-based method was introduced to identify secondary accidents. A linear regression model and two machine learning algorithms, including a back-propagation neural network (BPNN) and a least squares support vector machine (LSSVM), were implemented to explore the distance and time gap between the initial and secondary accidents using inputs of crash severity, violation category, weather condition, tow away, road surface condition, lighting, parties involved, traffic volume, duration, and shock wave speed generated by the primary accident. From the results, the linear regression model was inadequate in describing the effect of most variables and its goodness-of-fit and accuracy in prediction was relatively poor. In the training programs, the BPNN and LSSVM demonstrated adequate goodness-of-fit, though the BPNN was superior with a higher CORR and lower MSE. The BPNN model also outperformed the LSSVM in time prediction, while both failed to provide adequate distance prediction. Therefore, the BPNN model could be used to forecast the time gap between initial and secondary accidents, which could be used by decision makers and incident management agencies to prevent or reduce secondary collisions.}
}
@article{YANG201830,
title = {Driving behavior recognition using EEG data from a simulated car-following experiment},
journal = {Accident Analysis & Prevention},
volume = {116},
pages = {30-40},
year = {2018},
note = {Simulation of Traffic Safety in the Era of Advances in Technologies},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2017.11.010},
url = {https://www.sciencedirect.com/science/article/pii/S0001457517303974},
author = {Liu Yang and Rui Ma and H. Michael Zhang and Wei Guan and Shixiong Jiang},
keywords = {Driving behavior recognition, Electroencephalography (EEG), Car-following behavior, K-means, Support vector machine},
abstract = {Driving behavior recognition is the foundation of driver assistance systems, with potential applications in automated driving systems. Most prevailing studies have used subjective questionnaire data and objective driving data to classify driving behaviors, while few studies have used physiological signals such as electroencephalography (EEG) to gather data. To bridge this gap, this paper proposes a two-layer learning method for driving behavior recognition using EEG data. A simulated car-following driving experiment was designed and conducted to simultaneously collect data on the driving behaviors and EEG data of drivers. The proposed learning method consists of two layers. In Layer I, two-dimensional driving behavior features representing driving style and stability were selected and extracted from raw driving behavior data using K-means and support vector machine recursive feature elimination. Five groups of driving behaviors were classified based on these two-dimensional driving behavior features. In Layer II, the classification results from Layer I were utilized as inputs to generate a k-Nearest-Neighbor classifier identifying driving behavior groups using EEG data. Using independent component analysis, a fast Fourier transformation, and linear discriminant analysis sequentially, the raw EEG signals were processed to extract two core EEG features. Classifier performance was enhanced using the adaptive synthetic sampling approach. A leave-one-subject-out cross validation was conducted. The results showed that the average classification accuracy for all tested traffic states was 69.5% and the highest accuracy reached 83.5%, suggesting a significant correlation between EEG patterns and car-following behavior.}
}
@article{HALL2019148,
title = {Adequacy of negative binomial models for managing safety on rural local roads},
journal = {Accident Analysis & Prevention},
volume = {128},
pages = {148-158},
year = {2019},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2019.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518306808},
author = {Thomas Hall and Andrew P. Tarko},
keywords = {Rural local roads, Rural local intersections, Low-volume county roads, Low sample mean, Bivariate negative binomial model, Bivariate ordered probit model},
abstract = {Count models, such as negative binomial regression, are well-established statistical methods for analyzing road safety. Although count models are widely used for arterial roads, their application to rural local roads is sparse, partly due to the concern of possible estimation bias caused by low crash counts. This paper revisits the matter to further evaluate the suitability of negative binomial models for rural local roads with low crash frequencies, comparing the performance of the model to probabilistic regression (ordered probit) proposed in the past. The negative binomial model was estimated to predict crashes for rural local intersections and compared to predictions obtained from the ordered probit model. Bivariate versions of both models were applied to improve model efficiency by incorporating correlation between two severity outcomes, fatal/injury (FI) and property damage only (PDO) crashes. The estimated models included several significant variables with intuitive signs. These results are discussed in the paper to support the claim that both models are adequate. Furthermore, the cumulative sums of the model-predicted and observed crashes conditioned on the estimated effects were compared to detect any systematic bias in the results. Although both models showed similar performance and no obvious biases could be detected, the negative binomial model seemed to behave slightly better than the ordered probit model, demonstrating the model’s suitability in the analyzed case. The results point to the possibility of applying the Highway Safety Manual methodology to lower-volume county roads with focus shifted from individual high-crash locations to safety-deficient road features present at multiple locations.}
}
@article{GUO2019164,
title = {Modeling correlation and heterogeneity in crash rates by collision types using full bayesian random parameters multivariate Tobit model},
journal = {Accident Analysis & Prevention},
volume = {128},
pages = {164-174},
year = {2019},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2019.04.013},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518311576},
author = {Yanyong Guo and Zhibin Li and Pan Liu and Yao Wu},
keywords = {Crash rates, Collision types, Multivariate Tobit model, Random parameters, Full bayesian estimation},
abstract = {Crashes present different collision types. There usually exist unobserved risk factors which could jointly affect crash rates of different types, resulting in correlation and heterogeneity issues across observations. The primary objective of the study is to propose a novel random parameters multivariate Tobit (RPMV-Tobit) model for evaluating risk factors on crash rates of different collision types. Crash data from 367 freeway diverge areas in a three-year period were obtained for modeling. Three major types of collisions including rear-end, sideswipe, and angle collisions were considered. The RPMV-Tobit model was structured to simultaneously accommodate correlations between crash rates across collision types and unobserved heterogeneity across observations. The RPMV-Tobit model was compared with a multivariate Tobit (MV-Tobit) model, a random effect multivariate Tobit (REMV-Tobit) model, and independent univariate Tobit (IU-Tobit) models under the Bayesian framework. The results showed that MV-Tobit model outperforms the IU-Tobit models on fitting crash rates, indicating that accounting for the correlation between crash types can improve model fit. The RPMV-Tobit model and REMV-Tobit model perform better than the MV-Tobit model, suggesting that accounting for the unobserved heterogeneous can further improve model fit. The improvement of model performance with the RPMV-Tobit model is higher than that with the REMV-Tobit model. The impacts of each risk factor on crash rates were estimated and some differences were found across different collision types. The lane-balanced design, number of lanes on mainline, speed limit, and speed difference present significant heterogeneous effects on crash rates. Findings suggest that the RPMV-Tobit model is a superior approach for comprehensive crash rates modeling and traffic safety evaluation purposes.}
}
@article{LAVRENZ2018368,
title = {Time series modeling in traffic safety research},
journal = {Accident Analysis & Prevention},
volume = {117},
pages = {368-380},
year = {2018},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2017.11.030},
url = {https://www.sciencedirect.com/science/article/pii/S0001457517304268},
author = {Steven M. Lavrenz and Eleni I. Vlahogianni and Konstantina Gkritza and Yue Ke},
keywords = {Traffic safety, Time series analysis, Statistical methods, Econometric methods, Computational intelligence models, Crash data modeling},
abstract = {The use of statistical models for analyzing traffic safety (crash) data has been well-established. However, time series techniques have traditionally been underrepresented in the corresponding literature, due to challenges in data collection, along with a limited knowledge of proper methodology. In recent years, new types of high-resolution traffic safety data, especially in measuring driver behavior, have made time series modeling techniques an increasingly salient topic of study. Yet there remains a dearth of information to guide analysts in their use. This paper provides an overview of the state of the art in using time series models in traffic safety research, and discusses some of the fundamental techniques and considerations in classic time series modeling. It also presents ongoing and future opportunities for expanding the use of time series models, and explores newer modeling techniques, including computational intelligence models, which hold promise in effectively handling ever-larger data sets. The information contained herein is meant to guide safety researchers in understanding this broad area of transportation data analysis, and provide a framework for understanding safety trends that can influence policy-making.}
}
@article{ALGHUSON2019105300,
title = {Toward an integrated traffic law enforcement and network management in connected vehicle environment: Conceptual model and survey study of public acceptance},
journal = {Accident Analysis & Prevention},
volume = {133},
pages = {105300},
year = {2019},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2019.105300},
url = {https://www.sciencedirect.com/science/article/pii/S0001457519311261},
author = {Moahd Alghuson and Khaled Abdelghany and Ahmed Hassan},
keywords = {Traffic law enforcement, Transportation demand management, Connected vehicle, Driver performance monitoring},
abstract = {The increasing number of traffic accidents and their associated traffic congestion have prompted the development of innovative technologies to curb such problems. This paper proposes a novel score-based traffic law-enforcement and network management system (SLEM) that is based on connected vehicles (CV) technology. SLEM assigns a score to each driver which reflects her/his driving performance and compliance with traffic laws. The proposed system adopts a rewarding mechanism that rewards high-performing drivers and penalizes low-performing drivers who fail to obey the laws. The reward mechanism is in the form of a route guidance strategy that restricts low-score drivers from accessing certain roadway sections and time periods that are strategically selected in order to achieve an optimal traffic pattern in the network in which high-score drivers experience less congestion and a higher level of safety. A nationwide survey study was conducted to measure public acceptance of the proposed system. Another survey targeted a focused group of traffic operation and safety professionals. Based on the results of these surveys, a set of logistic regression models were developed to examine the sensitivity of public acceptance to policy and behavioral variables. The results showed that about 65.7 percent of the public and about 60.0 percent of professionals who participated in this study support the real-world implementation of SLEM.}
}
@article{ALREFAIE2019180,
title = {In a heart beat: Using driver’s physiological changes to determine the quality of a takeover in highly automated vehicles},
journal = {Accident Analysis & Prevention},
volume = {131},
pages = {180-190},
year = {2019},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2019.06.011},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518311217},
author = {Mohamed Taher Alrefaie and Stever Summerskill and Thomas W Jackon},
keywords = {Physiological data, Highly automated driving, Take-over, Driver performance, Heart rate, Pupil diameter, Autonomous vehicle, Accident prevention},
abstract = {Developing conditionally automated driving systems is on the rise. Vehicles with full longitudinal and latitudinal control will allow drivers to engage in secondary tasks without monitoring the roadway, but users may be required to resume vehicle control to handle critical hazards. The loss of driver’s situational awareness increases the potential for accidents. Thus, the automated systems need to estimate the driver’s ability to resume control of the driving task. The aim of this study was to assess the physiological behaviour (heart rate and pupil diameter) of drivers. The assessment was performed during two naturalistic secondary tasks. The tasks were the email and the twenty questions task in addition to a control group that did not perform any tasks. The study aimed at finding possible correlations between the driver’s physiological data and their responses to a takeover request. A driving simulator study was used to collect data from a total of 33 participants in a repeated measures design to examine the physiological changes during driving and to measure their takeover quality and response time. Secondary tasks induced changes on physiological measures and a small influence on response time. However, there was a strong observed correlation between the physiological measures and response time. Takeover quality in this study was assessed using two new performance measures called PerSpeed and PerAngle. They are identified as the mean percentage change of vehicle’s speed and heading angle starting from a take-over request time. Using linear mixed models, there was a strong interaction between task, heart rate and pupil diameter and PerSpeed, PerAngle and response time. This, in turn, provided a measurable understanding of a driver’s future responses to the automated system based on the driver’s physiological changes to allow better decision making. The present findings of this study emphasised the possibility of building a driver mental state model and prediction system to determine the quality of the driver's responses in a highly automated vehicle. Such results will reduce accidents and enhance the driver’s experience in highly automated vehicles.}
}
@article{PARSA2019202,
title = {Real-time accident detection: Coping with imbalanced data},
journal = {Accident Analysis & Prevention},
volume = {129},
pages = {202-210},
year = {2019},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2019.05.014},
url = {https://www.sciencedirect.com/science/article/pii/S0001457519301642},
author = {Amir Bahador Parsa and Homa Taghipour and Sybil Derrible and Abolfazl (Kouros) Mohammadian},
keywords = {Accident detection, Real-time data, Probabilistic neural network, Support vector machine, Machine learning},
abstract = {Detecting accidents is of great importance since they often impose significant delay and inconvenience to road users. This study compares the performance of two popular machine learning models, Support Vector Machine (SVM) and Probabilistic Neural Network (PNN), to detect the occurrence of accidents on the Eisenhower expressway in Chicago. Accordingly, since the detection of accidents should be as rapid as possible, seven models are trained and tested for each machine learning technique, using traffic condition data from 1 to 7 min after the actual occurrence. The main sources of data used in this study consist of weather condition, accident, and loop detector data. Furthermore, to overcome the problem of imbalanced data (i.e., underrepresentation of accidents in the dataset), the Synthetic Minority Oversampling TEchnique (SMOTE) is used. The results show that although SVM achieves overall higher accuracy, PNN outperforms SVM regarding the Detection Rate (DR) (i.e., percentage of correct accident detections). In addition, while both models perform best at 5 min after the occurrence of accidents, models trained at 3 or 4 min after the occurrence of an accident detect accidents more rapidly while performing reasonably well. Lastly, a sensitivity analysis of PNN for Time-To-Detection (TTD) reveals that the speed difference between upstream and downstream of accidents location is particularly significant to detect the occurrence of accidents.}
}
@article{KHATTAK2019151,
title = {Crash severity effects of adaptive signal control technology: An empirical assessment with insights from Pennsylvania and Virginia},
journal = {Accident Analysis & Prevention},
volume = {124},
pages = {151-162},
year = {2019},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2019.01.008},
url = {https://www.sciencedirect.com/science/article/pii/S0001457519300399},
author = {Zulqarnain H. Khattak and Michael D. Fontaine and Brian L. Smith and Jiaqi Ma},
keywords = {Adaptive signal control technology crashes, Injury severity, Intelligent transportation systems, Safety, Spatial transferability, Random parameters ordered probit models},
abstract = {Adaptive signal control technology (ASCT) is an intelligent transportation systems (ITS) technology that optimizes signal timings in real time to improve corridor flow. While a few past studies have examined the impact of ASCT on crash frequency, little is known about its effect on injury severity outcomes. Similarly, the impact of different types of ASCTs deployed across different states is also uncertain. This paper therefore, used ordered probit models with random parameters to estimate the injury severity outcomes resulting from ASCT deployment across Pennsylvania and Virginia. Two disparate systems deployed across the two different states were analyzed to assess whether they had similar impacts on injury severity, although signal timings are optimized using different algorithms by both systems. The estimation results revealed that both ASCT systems were associated with reductions in injury severity levels. Marginal effects showed that Type A ASCT systems reduced the propensity of severe plus moderate and minor injury crashes by 11.70% and 10.36% while type B ASCT reduced the propensity of severe plus moderate and minor injury crashes by 4.39% and 6.92%. Similarly, the ASCTs deployed across the two states were also observed to reduce injury severities. The combined best fit model also revealed a similar trend towards reductions in severe plus moderate and minor injury crashes by 5.24% and 9.91%. This model performed well on validation data with a low forecast error of 0.301 and was also observed to be spatially transferable. These results encourage the consideration of ASCT deployments at intersections with high crash severities and have practical implications for aiding agencies in making future deployment decisions about ASCT.}
}
@article{PARK2019230,
title = {A vehicle speed harmonization strategy for minimizing inter-vehicle crash risks},
journal = {Accident Analysis & Prevention},
volume = {128},
pages = {230-239},
year = {2019},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2019.04.014},
url = {https://www.sciencedirect.com/science/article/pii/S0001457519300314},
author = {Hyunjin Park and Cheol Oh},
keywords = {Risk estimation, Speed control, Risk map, Risk minimization, Vehicle trajectory data},
abstract = {Recent technological advancements have facilitated the implementation of speed harmonization based on connected and automated vehicles (CAV) to prevent crashes on the road. In addition, trajectory-level vehicle controls are receiving substantial attention as sensors, wireless communications, and control systems are rapidly advancing. This study proposes a novel vehicle speed control strategy to minimize inter-vehicle crash risks in automated driving environments. The proposed methodology consists of the following three components: a risk estimation module, a risk map construction module, and a vehicle speed control module. The essence of the proposed strategy is to adjust the subject vehicle speed based on an analysis of the interactions among a subject vehicle and the surrounding vehicles. Crash risks are quantified by a fault tree analysis (FTA) method to integrate the crash occurrence potential and crash severity at every time step. A crash risk map is then constructed by projecting the integrated risk of the subject vehicle into a two-dimensional space composed of relative speed and relative spacing data. Next, the vehicle speed is continuously controlled to reach the target speed using risk map analysis to prevent a crash. The performance of the proposed methodology is evaluated by a VISSIM simulator with various traffic congestion levels and market penetration rates (MPR) of controlled vehicles. For example, an approximate 50% reduction rate of the crash potential was achievable without a loss of the operational performance of the traffic stream when all vehicles were controlled by the proposed methodology under the level of service (LOS) C conditions. This study is meaningful in that vehicle speed control is performed for the purpose of speed harmonization in a traffic stream based on a comprehensive analysis of inter-vehicle risks. It is expected that the outcome of this study will be valuable for supporting the development of vehicle control systems for preventing crashes in automated driving environments.}
}
@article{LI2019143,
title = {Effects of an in-vehicle eco-safe driving system on drivers’ glance behaviour},
journal = {Accident Analysis & Prevention},
volume = {122},
pages = {143-152},
year = {2019},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2018.10.007},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518308169},
author = {Xiaomeng Li and Atiyeh Vaezipour and Andry Rakotonirainy and Sebastien Demmel},
keywords = {Eco-safe driving, In-vehicle HMI, Glance behaviour, Driver distraction, Traffic situation},
abstract = {We have designed a new in-vehicle eco-safe driving system and shown its effectiveness in prompting drivers to execute a fuel-saving and safe driving style (Vaezipour et al., 2018, submitted for publication). However, the system could also bring potential negative outcomes, i.e. driver distraction. This simulator study investigated drivers’ glance behaviours as indicators of driver distraction when using our Eco-Safe Human-Machine-Interface (HMI). Four types of eco-safe information display conditions (baseline, advice only, feedback only, both advice and feedback) were tested on different traffic situations with varied road traffic complexity. Results showed that the eco-safe HMI system did not cause visual distraction. In contrast, the advice only or feedback only information improved forward gazing on the roadway. In addition, drivers tended to adapt their visual scanning strategies according to the traffic situations. In the car-following situation they paid longer glances to the forward roadway, while in the intersections they spent more time to look at the HMI system. The findings indicated that our eco-safe driving system improved drivers’ eco-safe behaviours and meanwhile enhanced their visual attention on road while no evidence showed that drivers were distracted by it.}
}
@article{HUANG2020105392,
title = {Highway crash detection and risk estimation using deep learning},
journal = {Accident Analysis & Prevention},
volume = {135},
pages = {105392},
year = {2020},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2019.105392},
url = {https://www.sciencedirect.com/science/article/pii/S000145751930555X},
author = {Tingting Huang and Shuo Wang and Anuj Sharma},
keywords = {Crash detection, Crash prediction, Deep learning},
abstract = {Crash Detection is essential in providing timely information to traffic management centers and the public to reduce its adverse effects. Prediction of crash risk is vital for avoiding secondary crashes and safeguarding highway traffic. For many years, researchers have explored several techniques for early and precise detection of crashes to aid in traffic incident management. With recent advancements in data collection techniques, abundant real-time traffic data is available for use. Big data infrastructure and machine learning algorithms can utilize this data to provide suitable solutions for the highway traffic safety system. This paper explores the feasibility of using deep learning models to detect crash occurrence and predict crash risk. Volume, Speed and Sensor Occupancy data collected from roadside radar sensors along Interstate 235 in Des Moines, IA is used for this study. This real-world traffic data is used to design feature set for the deep learning models for crash detection and crash risk prediction. The results show that a deep model has better crash detection performance and similar crash prediction performance than state of the art shallow models. Additionally, a sensitivity analysis was conducted for crash risk prediction using data 1-minute, 5-minutes and 10-minutes prior to crash occurrence. It was observed that is hard to predict the crash risk of a traffic condition, 10 min prior to a crash.}
}
@article{WEN2019105249,
title = {Bayesian spatial-temporal model for the main and interaction effects of roadway and weather characteristics on freeway crash incidence},
journal = {Accident Analysis & Prevention},
volume = {132},
pages = {105249},
year = {2019},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2019.07.025},
url = {https://www.sciencedirect.com/science/article/pii/S0001457519304117},
author = {Huiying Wen and Xuan Zhang and Qiang Zeng and N.N. Sze},
keywords = {Freeway safety, Roadway alignment, Weather condition, Interaction effect, Spatio-Temporal model},
abstract = {This study attempts to examine the main and interaction effects of roadway and weather conditions on crash incidence, using the comprehensive crash, traffic and weather data from the Kaiyang Freeway in China in 2014. The dependent variable is monthly crash count on a roadway segment (with homogeneous horizontal and vertical profiles). A Bayesian spatio-temporal model is proposed to measure the association between crash frequency and possible risk factors including traffic composition, presence of curve and slope, weather conditions, and their interactions. The proposed model can also accommodate the unstructured random effect, and spatio-temporal correlation and interactions. Results of parameter estimation indicate that the interactions between wind speed and slope, between precipitation and curve, and between visibility and slope are significantly correlated to the increase in the freeway crash risk, while the interaction between precipitation and slope is significantly correlated to the reduction in the freeway crash risk, respectively. These findings are indicative of the design and implementation of real-time traffic management and control measures, e.g. variable message sign, that could mitigate the crash risk under the adverse weather conditions.}
}
@article{LIU2018211,
title = {Predicting interstate motor carrier crash rate level using classification models},
journal = {Accident Analysis & Prevention},
volume = {120},
pages = {211-218},
year = {2018},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2018.06.005},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518302227},
author = {Jundi Liu and Linda N. Boyle and Ashis G. Banerjee},
keywords = {Motor carrier safety, Crash rate, Variable selection, Classification and Regression Tree},
abstract = {Ensuring safe operations of large commercial vehicles (motor carriers) remains an important challenge, particularly in the United States. While the federal regulatory agency has instituted a compliance review-based rating method to encourage carriers to improve their safety levels, concerns have been expressed regarding the effectiveness of the current ratings. In this paper, we consider a crash rate level (high, medium, and low) rather than a compliance review-based rating (satisfactory, conditional satisfactory, and unsatisfactory). We demonstrate an automated way of predicting the crash rate levels for each carrier using three different classification models (Artificial Neural Network, Classification and Regression Tree (CART), and Support Vector Machine) and three separate variable selection methods (Empirical Evidence, Multiple Factor Analysis, Garson's algorithm). The predicted crash rate levels (high, low) are compared to the assigned levels based on the current safety rating method. The results indicate the feasibility of crash rate level as an effective measure of carrier safety, with CART having the best performance.}
}
@article{ZOU2018131,
title = {Visualization and analysis of mapping knowledge domain of road safety studies},
journal = {Accident Analysis & Prevention},
volume = {118},
pages = {131-145},
year = {2018},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2018.06.010},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518302744},
author = {Xin Zou and Wen Long Yue and Hai Le Vu},
keywords = {Road safety, Bibliometrics, Mapping knowledge domain, Visualization, VOSviewer, Sci2 Tool},
abstract = {Mapping knowledge domain (MKD) is an important application of visualization technology in Bibliometrics, which has been extensively applied in psychology, medicine, and information science. In this paper we conduct a systematic analysis of the development trend on road safety studies based on the Science Citation Index Expanded (SCIE) and Social Sciences Citation Index (SSCI) articles published between 2000 and 2018 using the MKD software tools VOSviewer and Sci2 Tool. Based on our analysis, we first present the annual numbers of articles, origin countries, main research organizations and groups as well as the source journals on road safety studies. We then report the collaborations among the main research organizations and groups using co-authorship analysis. Furthermore, we adopt the document co-citation analysis, keywords co-occurrence analysis, and burst detection analysis to visually explore the knowledge bases, topic distribution, research fronts and research trends on road safety studies. The proposed approach based on the visualized analysis of MKD can be used to establish a reference information and research basis for the application and development of methods in the domain of road safety studies. In particular, our results show that the knowledge bases (classical documents) of road safety studies in the last two decades have focused on five major areas of “Crash Frequency Data Analysis”, “Driver Behavior Questionnaire”, “Safety in Numbers for Walkers and Bicyclists”, “Road Traffic Injury and Prevention”, and “Driving Speed and Road Crashes”. Among the research topics, the five dominant clusters are “Causation and Injury Severity Analysis of Road Accidents”, “Epidemiologic Study and Prevention of Road Traffic Injury”, “Intelligent Transportation System and Active Safety”, “Young drivers’ driving behavior and psychology”, and “Older drivers’ psychological and physiological characteristics”. Finally, the burst keywords in research trends include Cycling, Intelligent Transportation Systems, and Distraction.}
}
@article{WANG2019105320,
title = {Crash prediction based on traffic platoon characteristics using floating car trajectory data and the machine learning approach},
journal = {Accident Analysis & Prevention},
volume = {133},
pages = {105320},
year = {2019},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2019.105320},
url = {https://www.sciencedirect.com/science/article/pii/S0001457519307468},
author = {Junhua Wang and Tianyang Luo and Ting Fu},
keywords = {Urban expressway, Floating car trajectory, Traffic platoon, Crash propensity prediction, Binary logistic regression, Support vector machine},
abstract = {Predicting crash propensity helps study safety on urban expressways in order to implement countermeasures and make improvements. It also helps identify and prevent crashes before they happen. However, collecting real-time wide-coverage traffic information for crash prediction has been challenging. More importantly, previous studies have failed to consider the characteristics of the traffic platoon (vehicle group) that the crash vehicle belongs to before the crash occurs. This paper aims to model crash propensity based on traffic platoon characteristics collected by the floating car method, which provides a time-efficient and reliable solution to collecting traffic information. Crash and floating car data are collected from the Middle Ring Expressway in Shanghai, China. Both the binary logistic model and the support vector machine are applied. A data preparation method, involving crash data filtering, floating car data filtering and data matching on the road network, is introduced for the safety analysis purpose. Results suggest that the traffic platoon information collected from floating cars accompanied works reasonably in predicting crashes on expressways. The support vector machine, with an overall accuracy of 85%, outperformed the binary logistic model which had an overall accuracy of 60%. Results further suggest the application of floating car technologies and the support vector machine in real-time crash prediction. Despite this, the study also concludes the merits of the binary logistic model over the support vector machine model in explaining the impact of different factors that contribute to crash occurrences.}
}
@article{SOLEIMANI201965,
title = {A Comprehensive Railroad-Highway Grade Crossing Consolidation Model: A Machine Learning Approach},
journal = {Accident Analysis & Prevention},
volume = {128},
pages = {65-77},
year = {2019},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2019.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518305736},
author = {Samira Soleimani and Saleh R. Mousa and Julius Codjoe and Michael Leitner},
keywords = {Highway-Rail Grade Crossing Consolidation, Closure Rating Formula, Safety, XGboost, Machine Learning},
abstract = {In the United States, there are approximately 212,000 highway-rail grade crossings, some of which experience vehicle-train incidents that often cause a massive financial burden, loss of life, and injury. In 2017, there were 2,108 highway-rail incidents resulting in 827 injuries and 307 fatalities nationwide. To eliminate collision risks, crossing grade separation and active alarm improvement are commonly used. Moreover, crossing closures are considered to be the most effective safety improvement program. While it may be very difficult, and in some cases impossible to close crossings, there are some incentive programs that facilitate the closure process. One of these programs is a working consolidation model that aims to determine crossing closure suitability. Using details of highway-rail grade crossings in the United States and applying an eXtreme Gradient Boosting (XGboost) algorithm, this paper proposes a data-driven consolidation model that takes into consideration a number of engineering variables. The results indicated an overall accuracy of 0.991 for the proposed model. In addition, the developed XGboost consolidation model reported the relative importance of the variables input to the model, offering an in-depth understanding of the model’s behavior. Finally, for the practical implementation of the model, a simplified version containing fewer variables was developed. A sensitivity analysis was performed considering the aggregate gain and the different correlation threshold values between variables. This analysis developed a simplified model utilizing 14 variables, with aggregated gain values of 75% and a correlation threshold of 0.9 which would perform similarly to the full model. Based on this model, 62% of current highway-rail grade crossings should be closed.}
}
@article{GIUMMARRA2020105333,
title = {A systematic review of the association between fault or blame-related attributions and procedures after transport injury and health and work-related outcomes},
journal = {Accident Analysis & Prevention},
volume = {135},
pages = {105333},
year = {2020},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2019.105333},
url = {https://www.sciencedirect.com/science/article/pii/S0001457519303781},
author = {Melita J. Giummarra and Georgina Lau and Genevieve Grant and Belinda J. Gabbe},
keywords = {Fault, Recovery, Road trauma, Transport injury, Pain, Mental health, PTSD, Depression, Anxiety},
abstract = {Attributions of fault are often associated with worse injury outcomes; however, the consistency and magnitude of these impacts is not known. This review examined the prognostic role of fault on health, mental health, pain and work outcomes after transport injury. A systematic search of five electronic databases (Medline, Embase, CINAHL, PsycINFO, Cochrane Library) yielded 16,324 records published between 2000 and January 2018. Eligibility criteria were: adult transport injury survivors; prospective design; multivariable analysis; fault-related factor analysed; pain, mental health, general health or work-related outcome. Citations (n = 10,558, excluding duplicates) and full text articles (n = 555) were screened manually (Reviewer 1), and using concurrent machine learning and text mining (Reviewer 2; using Abstrackr, WordStat and QDA miner). Data from 55 papers that met all inclusion criteria were extracted, papers were evaluated for risk of bias using the QUIPS tool, and overall level of evidence was assessed using the GRADE tool. There were six main fault-related factors classified as: fault or responsibility, fault-based compensation, lawyer involvement or litigation, blame or guilt, road user or position in vehicle, and impact direction. Overall there were inconsistent associations between fault and transport injury outcomes, and 60% of papers had high risk of bias. There was moderate evidence that fault-based compensation claims were associated with poorer health-related outcomes, and that lawyer involvement was associated with poorer work outcomes beyond 12 months post-injury. However, the evidence of negative associations between fault-based compensation claims and work-related outcomes was limited. Lawyer involvement and fault-based compensation claims were associated with adverse mental health outcomes six months post-injury, but not beyond 12 months. The most consistent associations between fault and negative outcomes were not for fault attributions, per se, but were related to fault-related procedures (e.g., lawyer engagement, fault-based compensation claims).}
}
@article{XING2020105343,
title = {Comparison of different models for evaluating vehicle collision risks at upstream diverging area of toll plaza},
journal = {Accident Analysis & Prevention},
volume = {135},
pages = {105343},
year = {2020},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2019.105343},
url = {https://www.sciencedirect.com/science/article/pii/S0001457519307584},
author = {Lu Xing and Jie He and Ye Li and Yina Wu and Jinghui Yuan and Xin Gu},
keywords = {Collision risk, Trajectory data, Toll plaza, Diverging area, Logistic regression, Non-Parametric model},
abstract = {Toll plazas with both Electronic Toll Collection (ETC) lane(s) and Manual Toll Collection (MTC) lane(s) could increase crash risks especially at upstream diverging areas because of frequency lane-change behaviors. This study develops the logistic regression (LR) model and five typical non-parametric models including, K-Nearest Neighbor (KNN), Artificial Neural Networks (ANN), Support Vector Machines (SVM), Decision Trees (DT), and Random Forest (RF) to examine the relationship between influencing factors and vehicle collision risk. Based on the vehicle trajectory data extracted from unmanned aerial vehicle (UAV) videos using an automated video analysis system, the unconstrained vehicle motion’s collision risk can be evaluated by the extended time to collision (ETTC). Results of model performance comparison indicate that not all non-parametric models have a better prediction performance than the LR model. Specifically, the KNN, SVM, DT and RF models have better model performance than LR model in model training, while the ANN model has the worst model performance. In model prediction, the accuracy of LR model is higher than that of other five non-parametric models under various ETTC thresholds conditions. The LR model implies a pretty good performance and its results also indicate that vehicle yields the higher collision risk when it drives on the left side of toll plaza diverging area and more dangerous situations could be found for an ETC vehicle. Moreover, the vehicle collision risks are positively associated with the speed of the following vehicle and the angle between the leading vehicle speed vector and X axis. Furthermore, the results of DT model show that three factors play important roles in classifying vehicle collision risk and the effects of them on collision risk are consistent with the results of LR model. These findings provide valuable information for accurate assessment of collision risk, which is a key step toward improving safety performance of the toll plaza diverging area.}
}
@article{YANG2019105296,
title = {Comparison among driving state prediction models for car-following condition based on EEG and driving features},
journal = {Accident Analysis & Prevention},
volume = {133},
pages = {105296},
year = {2019},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2019.105296},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518306547},
author = {Liu Yang and Wei Guan and Rui Ma and Xiaomeng Li},
keywords = {Driving behavior state, Electroencephalography, Independent component analysis, Feature extraction, Driving simulator},
abstract = {Risky driving states such as aggressive driving and unstable driving are the cause of many traffic accidents. Many studies have used either driving data or physiological data such as electroencephalography (EEG) to estimate and monitor driving states. However, few studies made comparison among those driving-feature-based, EEG-feature-based and hybrid-feature-based (combination of driving features and EEG features) models. Further, limited types of EEG features have been extracted and investigated in the existing studies. To fill these research gaps aforementioned, this study adopts two EEG analysis techniques (i.e., independent component analysis and brain source localization), two signal processing methods (i.e., power spectrum analysis and wavelets analysis) to extract twelve kinds of EEG features for the short-term driving state prediction. The prediction performance of driving features, EEG features and hybrid features of them was evaluated and compared. The results indicated that EEG-based model has better performance than driving-data-based model (i.e., 83.84% versus 71.59%) and the integrated model of driving features and the full brain regions features extracted by wavelet analysis outperforms other types of features with the highest accuracy of 86.27%.}
}
@article{ZHU2018152,
title = {Design and experiment verification of a novel analysis framework for recognition of driver injury patterns: From a multi-class classification perspective},
journal = {Accident Analysis & Prevention},
volume = {120},
pages = {152-164},
year = {2018},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2018.08.011},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518304524},
author = {Mengtao Zhu and Yunjie Li and Yinhai Wang},
keywords = {Multi-class imbalanced learning framework, Run-off-road crash, Injury severity pattern, Machine learning, Sensitivity analysis, Traffic safety},
abstract = {Detecting driver injury patterns is a typical classification problem. Crash data sets are highly skewed where fatalities and severe injuries are often less represented compared to other events. The severity prediction performance of the existing models is poor due to the highly imbalanced samples of different severity levels within a given dataset. This paper proposes a machine learning based analysis framework from a multi-class classification perspective for accurate recognition of the driver injury patterns. The proposed framework includes preprocessing, classification, evaluation and application of a given dataset. This framework is verified based on the three years single-vehicle ROR (run-off-road) crash records collected in Washington State from 2011 to 2013. At first, thirteen most important safety-related variables are recognized through random forests. Then, the four driver’s injury severity levels viz., fatal/serious injury, evident injury, possible injury, and no injury are predicted by integrating the decomposed binary neural network models to achieve better performance. Finally, a sensitivity analysis is carried out to interpret variables’ impacts on the decomposed injury severity levels. The study shows that lack of restraint, female drivers, truck usage, driver impairment, driver distraction, vehicle overturn (rollover), dawn/dusk, and overtaking are the leading factors contributing to the driver fatalities or severe injuries in a single-vehicle ROR crash. Most of the findings are consistent with the previous studies. The experimental results validate the effectiveness of the proposed framework which can be further applied for pattern recognition in traffic safety research.}
}
@article{SHI2018346,
title = {Key risk indicators for accident assessment conditioned on pre-crash vehicle trajectory},
journal = {Accident Analysis & Prevention},
volume = {117},
pages = {346-356},
year = {2018},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2018.05.007},
url = {https://www.sciencedirect.com/science/article/pii/S000145751830191X},
author = {X. Shi and Y.D. Wong and M.Z.F. Li and C. Chai},
keywords = {Key risk indicator, Risk exposure, Pre-accident risk, Vehicle risk},
abstract = {Accident events are generally unexpected and occur rarely. Pre-accident risk assessment by surrogate indicators is an effective way to identify risk levels and thus boost accident prediction. Herein, the concept of Key Risk Indicator (KRI) is proposed, which assesses risk exposures using hybrid indicators. Seven metrics are shortlisted as the basic indicators in KRI, with evaluation in terms of risk behaviour, risk avoidance, and risk margin. A typical real-world chain-collision accident and its antecedent (pre-crash) road traffic movements are retrieved from surveillance video footage, and a grid remapping method is proposed for data extraction and coordinates transformation. To investigate the feasibility of each indicator in risk assessment, a temporal-spatial case-control is designed. By comparison, Time Integrated Time-to-collision (TIT) performs better in identifying pre-accident risk conditions; while Crash Potential Index (CPI) is helpful in further picking out the severest ones (the near-accident). Based on TIT and CPI, the expressions of KRIs are developed, which enable us to evaluate risk severity with three levels, as well as the likelihood. KRI-based risk assessment also reveals predictive insights about a potential accident, including at-risk vehicles, locations and time. Furthermore, straightforward thresholds are defined flexibly in KRIs, since the impact of different threshold values is found not to be very critical. For better validation, another independent real-world accident sample is examined, and the two results are in close agreement. Hierarchical indicators such as KRIs offer new insights about pre-accident risk exposures, which is helpful for accident assessment and prediction.}
}
@article{WALI2019105277,
title = {Exploring microscopic driving volatility in naturalistic driving environment prior to involvement in safety critical events—Concept of event-based driving volatility},
journal = {Accident Analysis & Prevention},
volume = {132},
pages = {105277},
year = {2019},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2019.105277},
url = {https://www.sciencedirect.com/science/article/pii/S0001457519312369},
author = {Behram Wali and Asad J. Khattak and Thomas Karnowski},
keywords = {Naturalistic driving studies, Event-based volatility, Vehicular jerk, Crash, Near-crash, Crash propensity, Crash risk, Fixed and random parameters, Logit models},
abstract = {The sequence of instantaneous driving decisions and its variations, known as driving volatility, prior to involvement in safety critical events can be a leading indicator of safety. This study focuses on the component of “driving volatility matrix” related to specific normal and safety-critical events, named “event-based volatility.” The research issue is characterizing volatility in instantaneous driving decisions in the longitudinal and lateral directions, and how it varies across drivers involved in normal driving, crash, and/or near-crash events. To explore the issue, a rigorous quasi-experimental study design is adopted to help compare driving behaviors in normal vs unsafe outcomes. Using a unique real-world naturalistic driving database from the 2nd Strategic Highway Research Program (SHRP), a test set of 9593 driving events featuring 2.2 million temporal samples of real-world driving are analyzed. This study features a plethora of kinematic sensors, video, and radar spatiotemporal data about vehicle movement and therefore offers the opportunity to initiate such exploration. By using information related to longitudinal and lateral accelerations and vehicular jerk, 24 different aggregate and segmented measures of driving volatility are proposed that captures variations in extreme instantaneous driving decisions. In doing so, careful attention is given to the issue of intentional vs. unintentional volatility. The volatility indices, as leading indicators of near-crash and crash events, are then linked with safety critical events, crash propensity, and other event specific explanatory variables. Owing to the presence of unobserved heterogeneity and omitted variable bias, fixed- and random-parameter discrete choice models are developed that relate crash propensity to unintentional driving volatility and other factors. Statistically significant evidence is found that driver volatilities in near-crash and crash events are significantly greater than volatility in normal driving events. After controlling for traffic, roadway, and unobserved factors, the results suggest that greater intentional volatility increases the likelihood of both crash and near-crash events. A one-unit increase in intentional volatility is associated with positive vehicular jerk in longitudinal direction increases the chance of crash and near-crash outcome by 15.79 and 12.52 percentage points, respectively. Importantly, intentional volatility in positive vehicular jerk in lateral direction has more negative consequences than intentional volatility in positive vehicular jerk in longitudinal direction. Compared to acceleration/deceleration, vehicular jerk can better characterize the volatility in microscopic instantaneous driving decisions prior to involvement in safety critical events. Finally, the magnitudes of correlations exhibit significant heterogeneity, and that accounting for the heterogeneous effects in the modeling framework can provide more reliable and accurate results. The study demonstrates the value of quasi-experimental study design and big data analytics for understanding extreme driving behaviors in safe vs. unsafe driving outcomes.}
}
@article{OVIEDOTRESPALACIOS201767,
title = {Effects of road infrastructure and traffic complexity in speed adaptation behaviour of distracted drivers},
journal = {Accident Analysis & Prevention},
volume = {101},
pages = {67-77},
year = {2017},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2017.01.018},
url = {https://www.sciencedirect.com/science/article/pii/S0001457517300453},
author = {Oscar Oviedo-Trespalacios and Md. Mazharul Haque and Mark King and Simon Washington},
keywords = {Road infrastructure, Traffic complexity, Mobile phone distraction, High-fidelity driving simulator, Driver behaviour, Decision tree},
abstract = {The use of mobile phones while driving remains a major human factors issue in the transport system. A significant safety concern is that driving while distracted by a mobile phone potentially modifies the driving speed leading to conflicts with other road users and consequently increases crash risk. However, the lack of systematic knowledge of the mechanisms involved in speed adaptation of distracted drivers constrains the explanation and modelling of the extent of this phenomenon. The objective of this study was to investigate speed adaptation of distracted drivers under varying road infrastructure and traffic complexity conditions. The CARRS-Q Advanced Driving Simulator was used to test participants on a simulated road with different traffic conditions, such as free flow traffic along straight roads, driving in urbanized areas, and driving in heavy traffic along suburban roads. Thirty-two licensed young drivers drove the simulator under three phone conditions: baseline (no phone conversation), hands-free and handheld phone conversations. To understand the relationships between distraction, road infrastructure and traffic complexity, speed adaptation calculated as the deviation of driving speed from the posted speed limit was modelled using a decision tree. The identified groups of road infrastructure and traffic characteristics from the decision tree were then modelled with a Generalized Linear Mixed Model (GLMM) with repeated measures to develop inferences about speed adaptation behaviour of distracted drivers. The GLMM also included driver characteristics and secondary task demands as predictors of speed adaptation. Results indicated that complex road environments like urbanization, car-following situations along suburban roads, and curved road alignment significantly influenced speed adaptation behaviour. Distracted drivers selected a lower speed while driving along a curved road or during car-following situations, but speed adaptation was negligible in the presence of high visual cutter, indicating the prioritization of the driving task over the secondary task. Additionally, drivers who scored high on self-reported safe attitudes towards mobile phone usage, and who reported prior involvement in a road traffic crash, selected a lower driving speed in the distracted condition than in the baseline. The results aid in understanding how driving task demands influence speed adaptation of distracted drivers under various road infrastructure and traffic complexity conditions.}
}
@article{GOLD20183,
title = {Modeling take-over performance in level 3 conditionally automated vehicles},
journal = {Accident Analysis & Prevention},
volume = {116},
pages = {3-13},
year = {2018},
note = {Simulation of Traffic Safety in the Era of Advances in Technologies},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2017.11.009},
url = {https://www.sciencedirect.com/science/article/pii/S0001457517303962},
author = {Christian Gold and Riender Happee and Klaus Bengler},
keywords = {Automated driving, Take-Over, Modeling, Driver performance, Regression, Human factors},
abstract = {Taking over vehicle control from a Level 3 conditionally automated vehicle can be a demanding task for a driver. The take-over determines the controllability of automated vehicle functions and thereby also traffic safety. This paper presents models predicting the main take-over performance variables take-over time, minimum time-to-collision, brake application and crash probability. These variables are considered in relation to the situational and driver-related factors time-budget, traffic density, non-driving-related task, repetition, the current lane and driver’s age. Regression models were developed using 753 take-over situations recorded in a series of driving simulator experiments. The models were validated with data from five other driving simulator experiments of mostly unrelated authors with another 729 take-over situations. The models accurately captured take-over time, time-to-collision and crash probability, and moderately predicted the brake application. Especially the time-budget, traffic density and the repetition strongly influenced the take-over performance, while the non-driving-related tasks, the lane and drivers’ age explained a minor portion of the variance in the take-over performances.}
}
@article{XIONG201930,
title = {A forward collision avoidance algorithm based on driver braking behavior},
journal = {Accident Analysis & Prevention},
volume = {129},
pages = {30-43},
year = {2019},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2019.05.004},
url = {https://www.sciencedirect.com/science/article/pii/S0001457519300703},
author = {Xiaoxia Xiong and Meng Wang and Yingfeng Cai and Long Chen and Haneen Farah and Marjan Hagenzieker},
keywords = {Collision avoidance, Deceleration curve, Cluster analysis, Fuzzy logic, Driver braking behavior profile, Dynamic time warping},
abstract = {Measuring risk is critical for collision avoidance. The paper aims to develop an online risk level classification algorithm for forward collision avoidance systems. Assuming risk levels are reflected by braking profiles, deceleration curves from critical evasive braking events from the Virginia “100-car” database were first extracted. The curves are then clustered into different risk levels based on spectrum clustering, using curve distance and curve changing rate as dissimilarity metrics among deceleration curves. Fuzzy logic rules of safety indicators at critical braking onset for risk classification were then extracted according to the clustered risk levels. The safety indicators include time to collision, time headway, and final relative distance under emergency braking, which characterizes three kinds of uncertain critical conditions respectively. Finally, the obtained fuzzy risk level classification algorithm was tested and compared with other Automatic Emergency Braking (AEB) algorithms under Euro-NCAP testing scenarios in simulation. Results show the proposed algorithm is promising in balancing the objectives of avoiding collision and reducing interference with driver’s normal driving compared with other algorithms.}
}
@article{YU201970,
title = {Exploring crash mechanisms with microscopic traffic flow variables: A hybrid approach with latent class logit and path analysis models},
journal = {Accident Analysis & Prevention},
volume = {125},
pages = {70-78},
year = {2019},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2019.01.022},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518307073},
author = {Rongjie Yu and Yin Zheng and Mohamed Abdel-Aty and Zhen Gao},
keywords = {Crash mechanism, Microscopic traffic flow variables, Heterogeneous effects, Latent class logit, Path analysis},
abstract = {Understanding the occurrence mechanisms of crashes is critical for traffic safety improvement. Efforts have been investigated to reveal the crash mechanisms and analyze the contributing factors from the aspects of vehicle, driver, and operational perspectives. In this study, special attention has been paid to the operational level analyses while bridging the research gaps of: (1) failing to identify the heterogeneous impact of microscopic traffic flow variables on crash occurrence, and (2) focusing on correlation effects without further investigations for the causal relationships. A hybrid modeling approach with latent class logit (LCL) and path analysis (PA) models was proposed to account for the heterogeneous influencing effects and reveal the causal relationships between crash occurrence and microscopic traffic flow variables. Data from Shanghai urban expressway system were utilized for the empirical analyses. First, the LCL model has concluded four latent subsets of crash occurrence influencing factors. Then, PA models were conducted to identify the concurrent relationships (direct and indirect eﬀ ;ects) for the four sets of crash occurrence influencing factors separately. Finally, the results of the LCL model and PA models were compared and the crash-prone scenarios were inferred. And the potential safety improvement countermeasures were discussed.}
}
@article{PARSA2020105405,
title = {Toward safer highways, application of XGBoost and SHAP for real-time accident detection and feature analysis},
journal = {Accident Analysis & Prevention},
volume = {136},
pages = {105405},
year = {2020},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2019.105405},
url = {https://www.sciencedirect.com/science/article/pii/S0001457519311790},
author = {Amir Bahador Parsa and Ali Movahedi and Homa Taghipour and Sybil Derrible and Abolfazl (Kouros) Mohammadian},
keywords = {Accident detection, XGBoost, SHAP, Real time data, Machine learning},
abstract = {Detecting traffic accidents as rapidly as possible is essential for traffic safety. In this study, we use eXtreme Gradient Boosting (XGBoost)—a Machine Learning (ML) technique—to detect the occurrence of accidents using a set of real time data comprised of traffic, network, demographic, land use, and weather features. The data used from the Chicago metropolitan expressways was collected between December 2016 and December 2017, and it includes 244 traffic accidents and 6073 non-accident cases. In addition, SHAP (SHapley Additive exPlanation) is employed to interpret the results and analyze the importance of individual features. The results show that XGBoost can detect accidents robustly with an accuracy, detection rate, and a false alarm rate of 99 %, 79 %, and 0.16 %, respectively. Several traffic related features, especially difference of speed between 5 min before and 5 min after an accident, are found to have relatively more impact on the occurrence of accidents. Furthermore, a feature dependency analysis is conducted for three pairs of features. First, average daily traffic and speed after accidents/non-accidents time at the upstream location are interpreted jointly. Then, distance to Central Business District and residential density are analyzed. Finally, speed after accidents/non-accidents time at upstream location and speed after accidents/non-accidents time at downstream location are evaluated with respect to the model’s output.}
}